{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMFeatureExtractor(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "#         super(LSTMFeatureExtractor, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x shape: (batch, seq_len, features)\n",
    "#         lstm_out, (hn, cn) = self.lstm(x)  # lstm_out shape: (batch, seq_len, hidden_dim)\n",
    "#         return torch.squeeze(lstm_out)\n",
    "\n",
    "\n",
    "# class LSTMFeatureExtractor(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "#         super(LSTMFeatureExtractor, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # x shape: (batch, seq_len, features)\n",
    "#         _, (hn, _) = self.lstm(x)  # hn shape: (num_layers, batch, hidden_dim)\n",
    "        \n",
    "#         # Take the last layer's hidden state\n",
    "#         hn_last_layer = hn[-1, :, :]  # Shape: (batch, hidden_dim)\n",
    "        \n",
    "#         # If you specifically need the output to be 2048 dimensions but your hidden_dim is different,\n",
    "#         # you might consider adding a linear layer to map hidden_dim to 2048.\n",
    "#         # Ensure hidden_dim is set to 2048 if you want the output directly without transformation.\n",
    "#         return torch.squeeze(hn_last_layer)\n",
    "\n",
    "\n",
    "# class LSTMFeatureExtractorWithPooling(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "#         super(LSTMFeatureExtractorWithPooling, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # x shape: (batch, seq_len, features)\n",
    "#         lstm_out, _ = self.lstm(x)  # lstm_out shape: (batch, seq_len, hidden_dim)\n",
    "        \n",
    "#         # Apply mean pooling across timesteps\n",
    "#         # lstm_out shape after mean: (batch, hidden_dim)\n",
    "#         mean_pooled = torch.mean(lstm_out, dim=1)\n",
    "        \n",
    "#         return torch.squeeze(mean_pooled)\n",
    "\n",
    "# input_dim_vis = 2048  \n",
    "# input_dim_aud = 2048  \n",
    "# hidden_dim = 2048  \n",
    "# num_layers = 1    \n",
    "\n",
    "# feature_extractor_vis = LSTMFeatureExtractor(input_dim_vis, hidden_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EmotionDataset(Dataset):\n",
    "#     def __init__(self, X, y):\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.X)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.X[idx], self.y[idx]\n",
    "\n",
    "# def mean_pooling(batch_features_padded):\n",
    "#     return torch.mean(batch_features_padded, dim=1)\n",
    "\n",
    "# class FeatureDataset(Dataset):\n",
    "#     def __init__(self, dataframe, feature_type, base_path=\"../data/\"):\n",
    "#         \"\"\"\n",
    "#         feature_type: 'visual_features' or 'audio_features'\n",
    "#         \"\"\"\n",
    "#         self.dataframe = dataframe\n",
    "#         self.feature_type = feature_type\n",
    "#         self.base_path = base_path\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         file_path = self.dataframe.iloc[idx][self.feature_type]\n",
    "#         features = np.load(self.base_path + file_path)\n",
    "#         return torch.tensor(features, dtype=torch.float)\n",
    "# def collate_fn(batch):\n",
    "#     batch_features = [item for item in batch]\n",
    "#     batch_features_padded = pad_sequence(batch_features, batch_first=True)\n",
    "#     return mean_pooling(batch_features_padded)\n",
    "# # Emotion Classifier Model\n",
    "# class VisualClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(VisualClassifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(2048, 1024)\n",
    "#         self.bn1 = nn.BatchNorm1d(1024)\n",
    "#         self.dropout1 = nn.Dropout(0.5)\n",
    "#         self.fc2 = nn.Linear(1024, 256)\n",
    "#         self.bn2 = nn.BatchNorm1d(256)\n",
    "#         self.dropout2 = nn.Dropout(0.5)\n",
    "#         self.fc4 = nn.Linear(256, 4)  # Assuming 4 classes\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.fc1(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = F.relu(self.bn2(self.fc2(x)))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc4(x)\n",
    "#         return x\n",
    "# def calculate_accuracy(model, data_loader):\n",
    "#     model.eval()\n",
    "#     correct, total = 0, 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in data_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#     return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(batch_features_padded):\n",
    "    return torch.mean(batch_features_padded, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_type, base_path=\"../data/\"):\n",
    "        \"\"\"\n",
    "        feature_type: 'visual_features' or 'audio_features'\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.feature_type = feature_type\n",
    "        self.base_path = base_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.dataframe.iloc[idx][self.feature_type]\n",
    "        features = np.load(self.base_path + file_path)\n",
    "        return torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_features = [item for item in batch]\n",
    "    batch_features_padded = pad_sequence(batch_features, batch_first=True)\n",
    "    return mean_pooling(batch_features_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Classifier Model\n",
    "class VisualClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VisualClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(256, 4)\n",
    "        self.bn2 = nn.BatchNorm1d(4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=4, hidden_dim=256):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Classifier Model\n",
    "class AudialClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudialClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 16)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.bn2 = nn.BatchNorm1d(4)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, criterion, device, num_epochs=50, patience=10):\n",
    "\n",
    "    \"\"\"\n",
    "    Trains and validates the model.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The PyTorch model to train.\n",
    "    - dataloaders (dict): A dictionary containing 'train' and 'val' DataLoaders.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to use for training.\n",
    "    - criterion (torch.nn.Module): The loss function.\n",
    "    - num_epochs (int): The number of epochs to train for.\n",
    "    - patience (int): The patience for early stopping.\n",
    "    \"\"\"\n",
    "    best_val_f1 = -float('inf')  # Initialize best validation F1 score\n",
    "    patience_counter = 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders['val']:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_accuracy = np.mean(np.array(val_preds) == np.array(val_labels))\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='micro')\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1  \n",
    "            patience_counter = 0  \n",
    "            print(f\"Validation F1 improved. Saving model...\")\n",
    "            # torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "        else:\n",
    "            patience_counter += 1  # Increment patience counter\n",
    "            print(f'Validation F1 did not improve. Patience: {patience_counter}/{patience}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break  # Exit from the training loop\n",
    "\n",
    "        # Early stopping checks and updates based on validation loss, not shown here for brevity\n",
    "\n",
    "    # After training, print final best metrics\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}, Best Validation F1 Score: {best_val_f1:.4f}')\n",
    "    \n",
    "    return val_accuracy, best_val_f1, np.array(val_preds), np.array(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_pool_features(df, feature_types, base_path=\"../data/\"):\n",
    "    \"\"\"\n",
    "    Extracts features from specified columns in the DataFrame, applies mean pooling,\n",
    "    and updates the DataFrame with new columns for these processed features.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): The pandas DataFrame containing the features.\n",
    "    - feature_types (dict): A dictionary mapping from 'visual' and 'audio' to their respective column names in df.\n",
    "    - base_path (str): Base path where the feature files are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    for key, column in feature_types.items():\n",
    "        features_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_path = row[column]\n",
    "            features = np.load(f\"{base_path}{file_path}\")\n",
    "            features_list.append(np.mean(features, axis=0) if key != 'text' else features)\n",
    "        \n",
    "        df[f'extracted_{key}_features'] = features_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets_and_loaders(df, feature_columns, label_column='emotion_labels', batch_size = 4, test_size = 0.2):\n",
    "    \"\"\"\n",
    "    Prepares datasets and dataloaders for training and validation.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): The pandas DataFrame containing the pooled features and labels.\n",
    "    - feature_columns (list): List of column names for the features to be used.\n",
    "    - label_column (str): The column name where the label data is stored.\n",
    "    - batch_size (int): Batch size for the dataloaders.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary of dataloaders for training and validation for each feature type.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloaders = {}\n",
    "    y = torch.tensor(df[label_column].values, dtype = torch.long)\n",
    "\n",
    "    for feature_type in feature_columns:\n",
    "        X = np.array(df[feature_type].tolist(), dtype = np.float32)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = test_size, random_state = 42)\n",
    "        \n",
    "        train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train), y_train)\n",
    "        val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val), y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "        \n",
    "        dataloaders[f'{feature_type}_train'] = train_loader\n",
    "        dataloaders[f'{feature_type}_val'] = val_loader\n",
    "\n",
    "    return dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Class Imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/dataset.csv')\n",
    "\n",
    "labels = df['emotion_labels'].values\n",
    "classes = np.unique(labels)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights_tensor = class_weights_tensor.to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with extracted_visual_features:\n",
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.5336\n",
      "Training with extracted_audio_features:\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5560\n",
      "Training with extracted_text_features:\n",
      "Validation Accuracy: 0.3022, Best Validation F1 Score: 0.3209\n"
     ]
    }
   ],
   "source": [
    "model_aud = AudialClassifier()\n",
    "model_aud = model_aud.to(device)\n",
    "\n",
    "model_vis = VisualClassifier()\n",
    "model_vis = model_vis.to(device)\n",
    "\n",
    "\n",
    "model_text = TextClassifier()\n",
    "model_text = model_text.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "\n",
    "feature_types = {'visual': 'visual_features', 'audio': 'acoustic_features', 'text':'lexical_features'}\n",
    "extract_and_pool_features(df, feature_types)\n",
    "\n",
    "feature_columns = ['extracted_visual_features', 'extracted_audio_features','extracted_text_features']\n",
    "dataloaders = prepare_datasets_and_loaders(df, feature_columns, batch_size = 16)\n",
    "\n",
    "optimizer_aud = optim.Adam(model_aud.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "optimizer_vis = optim.Adam(model_vis.parameters(), lr = 0.001, weight_decay = 0)\n",
    "optimizer_text = optim.Adam(model_vis.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "\n",
    "\n",
    "models_optimizers = {\n",
    "    'extracted_visual_features': (model_vis, optimizer_vis),\n",
    "    'extracted_audio_features': (model_aud, optimizer_aud),\n",
    "    'extracted_text_features': (model_text, optimizer_text),\n",
    "}\n",
    "\n",
    "model_outputs = {}\n",
    "for feature_type, (model, optimizer) in models_optimizers.items():\n",
    "    print(f\"Training with {feature_type}:\")\n",
    "    val_accuracy, best_val_f1, val_preds, val_labels = train_model(\n",
    "        model, \n",
    "        {'train': dataloaders[f'{feature_type}_train'], 'val': dataloaders[f'{feature_type}_val']}, \n",
    "        optimizer, criterion, device=device, num_epochs=30, patience=15\n",
    "    )\n",
    "    model_outputs[feature_type] = {\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'val_preds': val_preds,\n",
    "        'val_labels': val_labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_outputs['extracted_text_features']['val_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAM GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your grid of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'optimizer': [optim.Adam],\n",
    "    'criterion': [nn.CrossEntropyLoss],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [4, 16, 32],\n",
    "    'patience': [5, 10, 15],\n",
    "    'weight_decay': [0, 1e-4, 1e-2],\n",
    "}\n",
    "\n",
    "\n",
    "def get_optimizer(optimizer_class, parameters, lr, weight_decay, momentum=None):\n",
    "    if optimizer_class == optim.Adam:\n",
    "        return optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_class == optim.SGD:\n",
    "        # Ensure momentum is provided for SGD; otherwise, default to 0\n",
    "        return optim.SGD(parameters, lr=lr, momentum=momentum if momentum is not None else 0, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def get_criterion(criterion_class):\n",
    "    if criterion_class == nn.CrossEntropyLoss:\n",
    "        return nn.CrossEntropyLoss()\n",
    "    elif criterion_class == nn.NLLLoss:\n",
    "        return nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(df, feature_columns, param_grid, device='cuda'):\n",
    "    max_vis_acc, max_aud_acc, max_text_acc = -np.inf, -np.inf, -np.inf\n",
    "    best_params_vis, best_params_aud, best_params_text = None, None, None\n",
    "\n",
    "    combinations = list(product(*param_grid.values()))\n",
    "\n",
    "    for combination in tqdm(combinations):\n",
    "        lr, optimizer_class, criterion_class, epochs, batch_size, patience, wd = combination\n",
    "        \n",
    "        dataloaders = prepare_datasets_and_loaders(df, feature_columns, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize models, optimizers, and criterion for each modality\n",
    "        model_vis = VisualClassifier().to(device)\n",
    "        optimizer_vis = optim.Adam(model_vis.parameters(), lr=lr, weight_decay=wd)\n",
    "        \n",
    "        model_aud = AudialClassifier().to(device)\n",
    "        optimizer_aud = optim.Adam(model_aud.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        model_text = TextClassifier().to(device)\n",
    "        optimizer_text = optim.Adam(model_text.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        \n",
    "        models_optimizers = {\n",
    "            'extracted_visual_features': (model_vis, optimizer_vis),\n",
    "            'extracted_audio_features': (model_aud, optimizer_aud),\n",
    "            'extracted_text_features': (model_text, optimizer_text),\n",
    "        }\n",
    "\n",
    "        for feature_type, (model, optimizer) in models_optimizers.items():\n",
    "            print(f\"\\nTraining {feature_type.split('_')[1].capitalize()} Model with lr={lr}, optimizer={optimizer_class.__name__}, criterion={criterion_class.__name__}, epochs={epochs}, batch_size={batch_size}, Patience={patience}, Weight decay={wd}\")\n",
    "            val_accuracy, best_val_f1, val_preds, val_labels = train_model(\n",
    "                model, \n",
    "                {'train': dataloaders[f'{feature_type}_train'], 'val': dataloaders[f'{feature_type}_val']}, \n",
    "                optimizer, criterion, device=device, num_epochs=epochs, patience=patience\n",
    "            )\n",
    "\n",
    "            # Check and update best parameters for each modality\n",
    "            if feature_type == 'extracted_visual_features' and val_accuracy > max_vis_acc:\n",
    "                max_vis_acc = val_accuracy\n",
    "                best_params_vis = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "            \n",
    "            elif feature_type == 'extracted_audio_features' and val_accuracy > max_aud_acc:\n",
    "                max_aud_acc = val_accuracy\n",
    "                best_params_aud = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "            \n",
    "            elif feature_type == 'extracted_text_features' and val_accuracy > max_text_acc:\n",
    "                max_text_acc = val_accuracy\n",
    "                best_params_text = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "\n",
    "    return best_params_vis, best_params_aud, best_params_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/162 [00:46<2:04:57, 46.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6754\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4030, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/162 [01:32<2:03:47, 46.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4366, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4627, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/162 [02:21<2:06:11, 47.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/162 [03:08<2:04:47, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/162 [03:57<2:05:16, 47.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4515\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 6/162 [04:57<2:15:12, 52.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/162 [05:45<2:10:40, 50.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5858, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 8/162 [06:31<2:05:58, 49.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/162 [07:15<2:00:55, 47.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 10/162 [07:26<1:31:46, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/162 [07:37<1:12:01, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/162 [07:48<58:25, 23.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/162 [08:00<48:49, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 14/162 [08:11<42:22, 17.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 15/162 [08:22<37:47, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6455, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4328, Best Validation F1 Score: 0.4701\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 16/162 [08:34<34:25, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 17/162 [08:45<32:15, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4590, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 18/162 [08:56<30:33, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 19/162 [09:02<25:37, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 20/162 [09:09<22:22,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4627, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 21/162 [09:15<19:58,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4440, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 22/162 [09:21<18:14,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 23/162 [09:28<17:05,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.4739\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4291, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 24/162 [09:34<16:13,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4254, Best Validation F1 Score: 0.4366\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 25/162 [09:40<15:31,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 26/162 [09:47<15:05,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27/162 [09:53<14:46,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 28/162 [11:01<56:11, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 29/162 [12:11<1:25:18, 38.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5597, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 30/162 [13:21<1:45:21, 47.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 31/162 [14:29<1:57:44, 53.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 32/162 [15:39<2:07:12, 58.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 33/162 [16:49<2:13:26, 62.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 34/162 [17:57<2:16:21, 63.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 35/162 [19:07<2:19:00, 65.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 36/162 [20:16<2:20:27, 66.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 37/162 [20:35<1:48:56, 52.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5000\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4664\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 38/162 [20:53<1:27:16, 42.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 39/162 [21:12<1:12:11, 35.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 40/162 [21:31<1:01:16, 30.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 41/162 [21:49<53:55, 26.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 42/162 [22:08<48:50, 24.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 43/162 [22:27<44:47, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 44/162 [22:45<42:13, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 45/162 [23:04<40:24, 20.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 46/162 [23:15<33:56, 17.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6493, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 47/162 [23:25<29:33, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6642\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 48/162 [23:36<26:33, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5000\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 49/162 [23:47<24:33, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 50/162 [23:57<22:52, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 51/162 [24:07<21:41, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6642\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 52/162 [24:18<20:38, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 53/162 [24:28<20:00, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 54/162 [24:39<19:33, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.5746\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 55/162 [25:20<35:27, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 56/162 [26:02<47:02, 26.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4440\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 57/162 [26:44<54:46, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 58/162 [27:25<59:13, 34.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 59/162 [28:07<1:02:47, 36.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3657, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5634, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 60/162 [28:49<1:04:58, 38.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 61/162 [29:30<1:05:45, 39.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 62/162 [30:12<1:06:41, 40.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4216, Best Validation F1 Score: 0.4403\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 63/162 [30:55<1:07:03, 40.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 64/162 [31:06<51:53, 31.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 65/162 [31:17<41:29, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 66/162 [31:28<34:11, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 67/162 [31:40<29:19, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 68/162 [31:52<25:48, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 69/162 [32:03<23:13, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 70/162 [32:15<21:13, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 71/162 [32:26<19:53, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 72/162 [32:38<19:01, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 73/162 [32:44<15:58, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 74/162 [32:51<13:53,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 75/162 [32:58<12:57,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 76/162 [33:05<11:53,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 77/162 [33:12<11:23,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 78/162 [33:20<11:07,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 79/162 [33:27<10:29,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 80/162 [33:34<10:10,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 81/162 [33:41<09:51,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 82/162 [34:56<36:54, 27.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 83/162 [36:13<55:44, 42.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4291, Best Validation F1 Score: 0.4664\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 84/162 [37:29<1:08:14, 52.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 85/162 [38:44<1:15:53, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 86/162 [40:00<1:21:27, 64.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3881, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 87/162 [41:16<1:24:50, 67.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 88/162 [42:31<1:26:11, 69.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 89/162 [43:47<1:27:12, 71.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 90/162 [45:04<1:28:08, 73.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 91/162 [45:24<1:08:01, 57.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6493, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 92/162 [45:45<54:10, 46.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 93/162 [46:05<44:24, 38.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 94/162 [46:25<37:26, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 95/162 [46:46<32:38, 29.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 96/162 [47:07<29:21, 26.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 97/162 [47:28<27:08, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 98/162 [47:49<25:25, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 99/162 [48:09<24:01, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 100/162 [48:21<20:00, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 101/162 [48:32<17:16, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 102/162 [48:43<15:18, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 103/162 [48:55<13:50, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 104/162 [49:06<12:50, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 105/162 [49:19<12:25, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 106/162 [49:30<11:42, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 107/162 [49:42<11:13, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 108/162 [49:53<10:48, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 109/162 [50:38<19:26, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.3993, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 110/162 [51:25<25:30, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3955\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 111/162 [52:11<29:19, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5634, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 112/162 [52:57<31:31, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6157\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4478\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 113/162 [53:44<33:00, 40.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3433\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 114/162 [54:30<33:46, 42.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 115/162 [55:15<33:48, 43.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5597, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 116/162 [1:40:47<10:51:32, 849.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4328\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 117/162 [1:42:10<7:44:43, 619.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 118/162 [1:42:31<5:22:46, 440.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 119/162 [1:42:52<3:45:17, 314.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2948, Best Validation F1 Score: 0.4440\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 120/162 [1:43:14<2:38:35, 226.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6082\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 121/162 [1:43:35<1:52:48, 165.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 122/162 [1:43:57<1:21:19, 122.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3843, Best Validation F1 Score: 0.4104\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 123/162 [1:44:17<59:26, 91.45s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 124/162 [1:44:34<43:44, 69.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 125/162 [1:44:54<33:33, 54.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4142\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 126/162 [1:45:14<26:31, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 127/162 [1:45:26<20:07, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 128/162 [1:45:39<15:51, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.3507, Best Validation F1 Score: 0.4328\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 129/162 [1:45:55<13:20, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 130/162 [1:46:09<11:18, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6567, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 131/162 [1:46:21<09:35, 18.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4104\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 132/162 [1:46:34<08:24, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 133/162 [1:46:44<07:11, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6381, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 134/162 [1:46:53<06:06, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.3918, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 135/162 [1:47:04<05:31, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 136/162 [1:48:45<16:58, 39.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 137/162 [1:50:26<24:03, 57.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4254\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 138/162 [1:52:31<31:05, 77.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 139/162 [1:54:26<34:07, 89.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4216, Best Validation F1 Score: 0.4515\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 140/162 [1:56:23<35:39, 97.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3955\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 141/162 [1:58:34<37:35, 107.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 142/162 [2:00:40<37:41, 113.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 143/162 [2:02:59<38:13, 120.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4067\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 144/162 [2:04:45<34:54, 116.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 145/162 [2:05:11<25:16, 89.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 146/162 [2:05:37<18:46, 70.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 147/162 [2:06:04<14:19, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 148/162 [2:06:32<11:18, 48.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 149/162 [2:06:58<09:03, 41.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4254\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 150/162 [2:07:25<07:28, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 151/162 [2:07:51<06:13, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 152/162 [2:08:18<05:17, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4142\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 153/162 [2:08:44<04:31, 30.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 154/162 [2:08:59<03:25, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 155/162 [2:09:14<02:37, 22.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.3806, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 156/162 [2:09:29<02:00, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 157/162 [2:09:43<01:31, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 158/162 [2:09:58<01:08, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 159/162 [2:10:13<00:50, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 160/162 [2:10:28<00:32, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 161/162 [2:10:44<00:15, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.3731, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [2:11:00<00:00, 48.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6082\n",
      "Best Visual Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 50, 'batch_size': 32, 'patience': 15, 'weight_decay': 0, 'validation_accuracy': 0.5447761194029851}\n",
      "Best Audio Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 30, 'batch_size': 4, 'patience': 15, 'weight_decay': 0, 'validation_accuracy': 0.5970149253731343}\n",
      "Best Text Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 30, 'batch_size': 32, 'patience': 10, 'weight_decay': 0, 'validation_accuracy': 0.6567164179104478}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vis_params, aud_params, text_params = grid_search(df, feature_columns, param_grid, device='cuda')\n",
    "print(\"Best Visual Model Params:\", vis_params)\n",
    "print(\"Best Audio Model Params:\", aud_params)\n",
    "print(\"Best Text Model Params:\", text_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.0001,\n",
       "  'optimizer': 'Adam',\n",
       "  'criterion': 'CrossEntropyLoss',\n",
       "  'epochs': 30,\n",
       "  'batch_size': 4,\n",
       "  'patience': 5,\n",
       "  'weight_decay': 0,\n",
       "  'validation_accuracy': 0.5335820895522388},\n",
       " {'learning_rate': 0.0001,\n",
       "  'optimizer': 'Adam',\n",
       "  'criterion': 'CrossEntropyLoss',\n",
       "  'epochs': 30,\n",
       "  'batch_size': 4,\n",
       "  'patience': 5,\n",
       "  'weight_decay': 0,\n",
       "  'validation_accuracy': 0.5783582089552238})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_params , aud_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of alignment temporally and lack of similarity of shapes of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexConcatModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=4):\n",
    "        super(ComplexConcatModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc5 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1336, 2944)\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 did not improve. Patience: 1/15\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 did not improve. Patience: 1/15\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 did not improve. Patience: 1/15\n",
      "Validation F1 did not improve. Patience: 2/15\n",
      "Validation F1 did not improve. Patience: 3/15\n",
      "Validation F1 did not improve. Patience: 4/15\n",
      "Validation F1 did not improve. Patience: 5/15\n",
      "Validation F1 did not improve. Patience: 6/15\n",
      "Validation F1 did not improve. Patience: 7/15\n",
      "Validation F1 did not improve. Patience: 8/15\n",
      "Validation F1 did not improve. Patience: 9/15\n",
      "Validation F1 did not improve. Patience: 10/15\n",
      "Validation F1 did not improve. Patience: 11/15\n",
      "Validation F1 did not improve. Patience: 12/15\n",
      "Validation F1 did not improve. Patience: 13/15\n",
      "Validation F1 did not improve. Patience: 14/15\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 did not improve. Patience: 1/15\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 did not improve. Patience: 1/15\n",
      "Validation F1 did not improve. Patience: 2/15\n",
      "Validation F1 did not improve. Patience: 3/15\n",
      "Validation F1 did not improve. Patience: 4/15\n",
      "Validation F1 did not improve. Patience: 5/15\n",
      "Validation F1 did not improve. Patience: 6/15\n",
      "Validation F1 did not improve. Patience: 7/15\n",
      "Validation F1 did not improve. Patience: 8/15\n",
      "Validation F1 did not improve. Patience: 9/15\n",
      "Validation F1 did not improve. Patience: 10/15\n",
      "Validation F1 did not improve. Patience: 11/15\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 improved. Saving model...\n",
      "Validation F1 did not improve. Patience: 1/15\n",
      "Validation F1 did not improve. Patience: 2/15\n",
      "Validation F1 did not improve. Patience: 3/15\n",
      "Validation F1 did not improve. Patience: 4/15\n",
      "Validation F1 did not improve. Patience: 5/15\n",
      "Validation F1 did not improve. Patience: 6/15\n",
      "Validation F1 did not improve. Patience: 7/15\n",
      "Validation F1 did not improve. Patience: 8/15\n",
      "Validation F1 did not improve. Patience: 9/15\n",
      "Validation F1 did not improve. Patience: 10/15\n",
      "Validation F1 did not improve. Patience: 11/15\n",
      "Validation F1 did not improve. Patience: 12/15\n",
      "Validation F1 did not improve. Patience: 13/15\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.6381\n"
     ]
    }
   ],
   "source": [
    "class ConcatDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        \"\"\"\n",
    "        features: Numpy array of concatenated features.\n",
    "        labels: Numpy array of labels.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Concatenate features\n",
    "concatenated_features = np.hstack((\n",
    "    np.array(df['extracted_visual_features'].tolist()),\n",
    "    np.array(df['extracted_audio_features'].tolist()),\n",
    "    np.array(df['extracted_text_features'].tolist())\n",
    "))\n",
    "\n",
    "print(concatenated_features.shape)\n",
    "# Assuming 'emotion_labels' is your label column in the DataFrame\n",
    "labels = df['emotion_labels'].values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(concatenated_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state = 0,max_iter=1000).fit(X_train, y_train)\n",
    "yPred_clf = clf.predict(X_val)\n",
    "# print(accuracy_score(y_val, yPred_clf))\n",
    "\n",
    "\n",
    "train_dataset = ConcatDataset(X_train, y_train)\n",
    "val_dataset = ConcatDataset(X_val, y_val)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size = 16, shuffle = True),\n",
    "    'val': DataLoader(val_dataset, batch_size = 16, shuffle = False)\n",
    "}\n",
    "\n",
    "# Assuming the model and other necessary variables like optimizer and criterion are defined\n",
    "model = EnhancedConcatModel(input_dim = concatenated_features.shape[1]).to(device)  # Update input_dim as needed\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "\n",
    "val_accuracy, best_val_f1, val_preds, val_labels = train_model(\n",
    "    model = model,\n",
    "    dataloaders = dataloaders,\n",
    "    optimizer = optimizer,\n",
    "    criterion = criterion,  # Make sure this is defined as shown before\n",
    "    device = device,\n",
    "    num_epochs = 50,\n",
    "    patience = 15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIhCAYAAADejQtoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcq0lEQVR4nO3de3zP9f//8ft7s703zDKy2cyMIedj5BAiQkTqUw4V8ZEcKk18vhKbPmWlksqhoigRoSSnnCKFGpIlHxKiD3NmOQ3b8/eHn/fH2xw23u+93u11u34ur8un9+v4eL1fGw+P5+HlMMYYAQAAwDb8rA4AAAAAuYsEEAAAwGZIAAEAAGyGBBAAAMBmSAABAABshgQQAADAZkgAAQAAbIYEEAAAwGZIAAEAAGyGBBB/O5s2bdLjjz+u2NhYBQUFqWDBgqpZs6ZGjhypI0eOePXaP/30kxo3bqzQ0FA5HA6NHj3a49dwOBxKTEz0+HmvZ/LkyXI4HHI4HFqxYkWW7cYYxcXFyeFwqEmTJjd0jXHjxmny5Mk5OmbFihVXjelGzZgxQ5UqVVJwcLAcDoc2btzosXNfqlSpUq7v9FpLTr+Tqzl16pQSExOz/V3t2rXLFcPVfua6d+/u2seTmjRpcsM/R6VKlVK3bt08Gg9gN/msDgDIiQkTJqhPnz4qX768Bg4cqIoVK+rcuXNat26d3n33Xa1Zs0ZffPGF167fvXt3nTx5UtOnT1fhwoVVqlQpj19jzZo1KlGihMfPm10hISH64IMPsvzlvHLlSv3+++8KCQm54XOPGzdORYsWzdFf3jVr1tSaNWtUsWLFG77upQ4ePKhHH31ULVu21Lhx4+R0OlWuXDmPnPtyX3zxhdLT012fJ06cqA8++ECLFi1SaGioa32ZMmU8cr1Tp05p+PDhkpSj5CokJESTJ0/WsGHD5Of3v7rAiRMnNHPmTBUqVEhpaWkeiRGAbyABxN/GmjVr1Lt3bzVv3lxz5syR0+l0bWvevLkGDBigRYsWeTWGX375RT179lSrVq28do077rjDa+fOjocfflhTp07V2LFjVahQIdf6Dz74QPXq1cu1RODcuXNyOBwqVKiQR7+Tbdu26dy5c3rkkUfUuHFjj5zz1KlTyp8/f5b1NWrUcPt88eezVq1aKlq0qEeu7QkPP/ywJk6cqGXLlql58+au9TNmzFBGRobat2+vTz75xMIIAXgaTcD42xgxYoQcDofef/99t+TvosDAQN13332uz5mZmRo5cqRuu+02OZ1OFStWTI899pj+/PNPt+OaNGmiypUrKzk5WXfeeafy58+v0qVL65VXXlFmZqak/zWPnj9/XuPHj3drEktMTLxi89jFY3bt2uVat3z5cjVp0kRFihRRcHCwSpYsqQceeECnTp1y7XOl5rhffvlF7dq1U+HChRUUFKTq1avro48+ctvnYlPpp59+qiFDhigyMlKFChXS3Xffra1bt2bvS5bUqVMnSdKnn37qWnf8+HHNnj1b3bt3v+Ixw4cPV926dRUWFqZChQqpZs2a+uCDD2SMce1TqlQpbd68WStXrnR9fxcrqBdjnzJligYMGKCoqCg5nU5t3749SxPwoUOHFB0drfr16+vcuXOu8//6668qUKCAHn300aveW7du3dSwYUNJF5Key5uz586dq3r16il//vwKCQlR8+bNtWbNGrdzXHzeGzZs0IMPPqjChQvfVAXPGKNx48apevXqCg4OVuHChfXggw9qx44drn2mT58uh8OhMWPGuB2bkJAgf39/LVmyRLt27dKtt94q6cLzuPgdZ6faWr58edWvX18ffvih2/oPP/xQHTp0cKtWXpTd3y9jjEaOHKmYmBgFBQWpZs2aWrhw4RXjSEtL03PPPafY2FgFBgYqKipK/fv318mTJ697DwByyAB/A+fPnzf58+c3devWzfYxTzzxhJFk+vXrZxYtWmTeffddc+utt5ro6Ghz8OBB136NGzc2RYoUMWXLljXvvvuuWbJkienTp4+RZD766CNjjDEHDhwwa9asMZLMgw8+aNasWWPWrFljjDEmISHBXOlXadKkSUaS2blzpzHGmJ07d5qgoCDTvHlzM2fOHLNixQozdepU8+ijj5qjR4+6jpNkEhISXJ//85//mJCQEFOmTBnz8ccfm/nz55tOnToZSebVV1917ffNN98YSaZUqVKmS5cuZv78+ebTTz81JUuWNGXLljXnz5+/5vd1Md7k5GTz6KOPmjp16ri2jR8/3hQoUMCkpaWZSpUqmcaNG7sd261bN/PBBx+YJUuWmCVLlph///vfJjg42AwfPty1z4YNG0zp0qVNjRo1XN/fhg0b3GKPiooyDz74oJk7d66ZN2+eOXz4sGvbN9984zrXd999Z/Lly2eeffZZY4wxJ0+eNBUrVjS33XabOXHixFXvcfv27Wbs2LFGkhkxYoRZs2aN2bx5szHGmKlTpxpJpkWLFmbOnDlmxowZplatWiYwMNCsWrXKdY6LzzsmJsb861//MkuWLDFz5sy55nd7+bGX/vz17NnTBAQEmAEDBphFixaZadOmmdtuu82Eh4eb1NRU135PPvmkCQwMNMnJycYYY5YtW2b8/PzMCy+8YIwx5syZM2bRokVGkunRo4frO96+fftV49m5c6eRZF577TXzwQcfmKCgIHPkyBFjzIWfO0lm+fLlpm/fvll+xrP7+3Xxnnv06GEWLlxo3n//fRMVFWUiIiLcfo5OnjxpqlevbooWLWpGjRplli5dat566y0TGhpqmjZtajIzM137xsTEmK5du2brOwdwZSSA+FtITU01kkzHjh2ztf+WLVuMJNOnTx+39T/88IORZJ5//nnXusaNGxtJ5ocffnDbt2LFiuaee+5xWyfJ9O3b121ddhPAWbNmGUlm48aN14z98gSwY8eOxul0mt27d7vt16pVK5M/f35z7NgxY8z/kqjWrVu77ffZZ58ZSa6E9WouTQAvnuuXX34xxhhz++23m27duhljzBUTwEtlZGSYc+fOmRdffNEUKVLE7S/uqx178XqNGjW66rZLE0BjjHn11VeNJPPFF1+Yrl27muDgYLNp06Zr3uOl55s5c6ZbzJGRkaZKlSomIyPDtf6vv/4yxYoVM/Xr13etu/i8hw0bdt1rXe7yBPDiPyreeOMNt/327NljgoODzaBBg1zrzpw5Y2rUqGFiY2PNr7/+asLDw03jxo3dEvuDBw9m+fm5lksTwL/++ssULFjQjBkzxhhjzMCBA01sbKzJzMzMkgBm9/fr6NGjJigoyNx///1u+33//fdGktvPQlJSkvHz83MluBdd/L1ZsGCBax0JIHDzaAJGnvTNN99IUpbmrzp16qhChQpatmyZ2/qIiAjVqVPHbV3VqlX1xx9/eCym6tWrKzAwUE888YQ++ugjtya+a1m+fLmaNWum6Ohot/XdunXTqVOnsjRRXtoMLl24D0k5upfGjRurTJky+vDDD5WSkqLk5OSrNv9ejPHuu+9WaGio/P39FRAQoGHDhunw4cM6cOBAtq/7wAMPZHvfgQMH6t5771WnTp300Ucf6Z133lGVKlWyffyltm7dqr179+rRRx91GwRRsGBBPfDAA1q7dq1bM31OY72aefPmyeFw6JFHHtH58+ddS0REhKpVq+Y2mtfpdOqzzz7T4cOHVbNmTRlj9Omnn8rf3/+m45Au3Os//vEPffjhhzp//rw+/vhjPf7441fs3pDd3681a9bozJkz6tKli9t+9evXV0xMjNu6efPmqXLlyqpevbrbd3HPPfd4fBQ4APoA4m+iaNGiyp8/v3bu3Jmt/Q8fPixJKl68eJZtkZGRru0XFSlSJMt+TqdTp0+fvoFor6xMmTJaunSpihUrpr59+6pMmTIqU6aM3nrrrWsed/jw4avex8Xtl7r8Xi72l8zJvTgcDj3++OP65JNP9O6776pcuXK68847r7jvjz/+qBYtWki6MEr7+++/V3JysoYMGZLj617pPq8VY7du3XTmzBlFRERcs+/f9Vzv5yUzM1NHjx694VivZv/+/TLGKDw8XAEBAW7L2rVrdejQIbf94+LidOedd7qSKk/EcKkePXpow4YNevnll3Xw4MGr9h/M7u/Xxf+PiIjIst/l6/bv369NmzZl+R5CQkJkjMnyXQC4OYwCxt+Cv7+/mjVrpoULF+rPP/+87jQpF5Ogffv2Zdl37969Hh2BGRQUJElKT093G5xypb+w7rzzTt15553KyMjQunXr9M4776h///4KDw9Xx44dr3j+IkWKaN++fVnW7927V5K8Npq0W7duGjZsmN599129/PLLV91v+vTpCggI0Lx581zfhSTNmTMnx9fMyVxz+/btU9++fVW9enVt3rxZzz33nN5+++0cX1Ny/3m53N69e+Xn56fChQvfcKxXU7RoUTkcDq1ateqKA5suXzdx4kTNnz9fderU0ZgxY/Twww+rbt26Nx3HRQ0aNFD58uX14osvqnnz5lmqzhdl9/fr4n6pqalZzpGamuo2jVLRokUVHBycZSDKpdsBeA4VQPxtDB48WMYY9ezZU2fPns2y/dy5c/rqq68kSU2bNpWkLFNXJCcna8uWLWrWrJnH4rr4l9imTZvc1l+M5Ur8/f1Vt25djR07VpK0YcOGq+7brFkzLV++3JXwXfTxxx8rf/78Xps2JioqSgMHDlTbtm3VtWvXq+7ncDiUL18+t6bI06dPa8qUKVn29VRVNSMjQ506dZLD4dDChQuVlJSkd955R59//vkNna98+fKKiorStGnT3EYunzx5UrNnz3aNDPa0Nm3ayBij//73v6pdu3aW5dIm7ZSUFD399NN67LHHtGrVKlWtWlUPP/ywW2XyRqq9l3vhhRfUtm1bDRgw4Kr7ZPf364477lBQUJCmTp3qtt/q1auzdElo06aNfv/9dxUpUuSK34U35twE7IwKIP426tWrp/Hjx6tPnz6qVauWevfurUqVKuncuXP66aef9P7776ty5cpq27atypcvryeeeELvvPOO/Pz81KpVK+3atUtDhw5VdHS0nn32WY/F1bp1a4WFhalHjx568cUXlS9fPk2ePFl79uxx2+/dd9/V8uXLde+996pkyZI6c+aMq9px9913X/X8CQkJmjdvnu666y4NGzZMYWFhmjp1qubPn6+RI0decYoOT3nllVeuu8+9996rUaNGqXPnznriiSd0+PBhvf7661esaFWpUkXTp0/XjBkzVLp0aQUFBd1Qv72EhAStWrVKixcvVkREhAYMGKCVK1eqR48eqlGjhmJjY3N0Pj8/P40cOVJdunRRmzZt1KtXL6Wnp+u1117TsWPHsvU93IgGDRroiSee0OOPP65169apUaNGKlCggPbt26fvvvtOVapUUe/evXXy5Ek99NBDio2N1bhx4xQYGKjPPvtMNWvW1OOPP+6qtoaEhCgmJkZffvmlmjVrprCwMBUtWjRHydMjjzyiRx555Jr7ZPf3q3Dhwnruuef00ksv6Z///Kf+8Y9/aM+ePUpMTMzSBNy/f3/Nnj1bjRo10rPPPquqVasqMzNTu3fv1uLFizVgwACPVjsB27NyBApwIzZu3Gi6du1qSpYsaQIDA02BAgVMjRo1zLBhw8yBAwdc+2VkZJhXX33VlCtXzgQEBJiiRYuaRx55xOzZs8ftfI0bNzaVKlXKcp2uXbuamJgYt3W6wihgY4z58ccfTf369U2BAgVMVFSUSUhIMBMnTnQbBbxmzRpz//33m5iYGON0Ok2RIkVM48aNzdy5c7Nc4/JRnCkpKaZt27YmNDTUBAYGmmrVqplJkya57XOl0a3G/G+k5+X7X+7SUcDXcqWRvB9++KEpX768cTqdpnTp0iYpKcl88MEHbvdvjDG7du0yLVq0MCEhIa6pVK4V+6XbLo4CXrx4sfHz88vyHR0+fNiULFnS3H777SY9Pf2q8V/rWnPmzDF169Y1QUFBpkCBAqZZs2bm+++/d9vnSlO5ZNfVjv3www9N3bp1TYECBUxwcLApU6aMeeyxx8y6deuMMcY88sgjJn/+/K4pay6aOXOmkWTefPNN17qlS5eaGjVqGKfTaSRdc7TspaOAr+VK08Bk9/crMzPTJCUlmejoaBMYGGiqVq1qvvrqK9O4ceMsP0cnTpwwL7zwgilfvrwJDAw0oaGhpkqVKubZZ591mxKHUcDAzXMYc0l7BwAAAPI8+gACAADYDAkgAACAzZAAAgAA2AwJIAAAgM2QAAIAANgMCSAAAIDNkAACAADYTJ58E0j9kd9aHQJy0ZNNc/bWB/y93R4ZZnUIyEXtRq+yOgTkom0jW1p27eAa/bx27tM/jfHauW8UFUAAAACbyZMVQAAAgBxx2KsmRgIIAADgcFgdQa6yV7oLAAAAKoAAAAB2awK2190CAACABBAAAEAOh/eWm5CUlCSHw6H+/fu71hljlJiYqMjISAUHB6tJkybavHlzjs5LAggAAOCDkpOT9f7776tq1apu60eOHKlRo0ZpzJgxSk5OVkREhJo3b66//vor2+cmAQQAAHD4eW+5ASdOnFCXLl00YcIEFS5c2LXeGKPRo0dryJAh6tChgypXrqyPPvpIp06d0rRp07J9fhJAAAAAL0pPT1daWprbkp6efs1j+vbtq3vvvVd333232/qdO3cqNTVVLVq0cK1zOp1q3LixVq9ene2YSAABAAC82AcwKSlJoaGhbktSUtJVQ5k+fbo2bNhwxX1SU1MlSeHh4W7rw8PDXduyg2lgAAAAvDgNzODBgxUfH++2zul0XnHfPXv26JlnntHixYsVFBR01XM6LhtcYozJsu5aSAABAAC8yOl0XjXhu9z69et14MAB1apVy7UuIyND3377rcaMGaOtW7dKulAJLF68uGufAwcOZKkKXgtNwAAAAD4yDUyzZs2UkpKijRs3upbatWurS5cu2rhxo0qXLq2IiAgtWbLEdczZs2e1cuVK1a9fP9vXoQIIAADgI0JCQlS5cmW3dQUKFFCRIkVc6/v3768RI0aobNmyKlu2rEaMGKH8+fOrc+fO2b4OCSAAAMDf6FVwgwYN0unTp9WnTx8dPXpUdevW1eLFixUSEpLtc5AAAgAA+LAVK1a4fXY4HEpMTFRiYuINn5MEEAAA4CZf2fZ38/epdwIAAMAjqAACAAD8jfoAegIJIAAAAE3AAAAAyMuoAAIAANisCdhedwsAAAAqgAAAAFQAAQAAkKdRAQQAAPBjFDAAAADyMCqAAAAANusDSAIIAADARNAAAADIy6gAAgAA2KwJ2F53CwAAACqAAAAA9AEEAABAnkYFEAAAgD6AAAAAyMt8NgE8f/68du/ebXUYAADADhwO7y0+yGebgDdv3qyaNWsqIyPD6lAAAEBeRxMwAAAA8jLLKoA1a9a85vbTp0/nUiQAAMD2fLSp1lssSwB//fVXdezYUbGxsVfcvm/fPm3bti2XowIAAMj7LEsAK1eurLp166p3795X3L5x40ZNmDAhl6MCAAC2RB/A3NGwYUNt3br1qttDQkLUqFGjXIwIAADAHiyrAI4ePfqa28uUKaNvvvkmd4IBAAD2ZrM+gPaqdwIAAMD6BHDRokX67rvvXJ/Hjh2r6tWrq3Pnzjp69KiFkQEAANtw+Hlv8UGWRzVw4EClpaVJklJSUjRgwAC1bt1aO3bsUHx8vMXRAQAAW7BZAmj5m0B27typihUrSpJmz56tNm3aaMSIEdqwYYNat25tcXQAAAB5j+VpaWBgoE6dOiVJWrp0qVq0aCFJCgsLc1UGAQAAvIp3Aeeuhg0bKj4+Xg0aNNCPP/6oGTNmSJK2bdumEiVKWBwdAABA3mN5AjhmzBj16dNHs2bN0vjx4xUVFSVJWrhwoVq2bGlxdL7l0brRalKuqEoWCdbZc5lK2ZumcSt3aveR/702b/WgK8+dOGbFDk378c/cChUesnvLJq2Z/5lSd/6mE8cO68Fnh6t87Qau7V+9O1KbVi12OyayzG16/MUxuR0qvKBnx3t1cP++LOtbtfuHevUfbEFE8JROd0SrU72SKlE4WJL02/4TGrt0u77desi1z1PN4/RQ3RIKDQ7Qz7uPa/icX7V9/wmrQs77fLSvnrdYngCWLFlS8+bNy7L+zTfftCAa31YjOlSzf9qrLfv+kr+fQ70aldLof1RR5w/X6cy5TElSm7Fr3I6pFxumwa3KacUlf6jg7+Ns+hmFlyytao3v0ezRw6+4T+mqt6ttr4Guz/75LP+1hoe8/u4nyszMcH3evfN3JTzXW/WbNLcwKnhC6vEzemPhVv1x6EIXqPtrRWlc15pq/9Zqbd9/Qj2bxOrxO0vp/z5L0c6DJ9WnWRlN6llbLV9bpZPpGdc5O3B9lv9NsWHDBgUEBKhKlSqSpC+//FKTJk1SxYoVlZiYqMDAQIsj9B3xs35x+/zygm1a8FQ93RYeoo1/HpckHTl5zm2fO8sW0Ybdx7T3+JlcixOeE1e9juKq17nmPvkCAlTwlrBcigi5KfSWwm6fZ0+bpIjIEqpcrZZFEcFTvtly0O3zm1//pk71olW9ZKi27z+hrg1jNH7571r8y35J0qAZm7RmWFO1qR6pGT/ssSLkvM9H++p5i+X1zl69emnbtm2SpB07dqhjx47Knz+/Zs6cqUGDBlkcnW8r4PSXJKWdOXfF7YXzB6h+6TB9tSk1N8NCLvtjy896s/eDGj+gq+ZPeEMnjzN/Zl507tw5rVyyUM1atZPDZn9R5XV+DuneahHKH5hPP/1xTNFhwSpWKEjfbftfy825DKMfdxxRzZhbrAsUeYrlFcBt27apevXqkqSZM2eqUaNGmjZtmr7//nt17Njxuq+MS09PV3p6utu6zPNn5Zcv71cOn25aRhv3HNeO/9+EcLnWlcN16myGVm6j+TevKlPtdt1Wt5FCi4br2MFUrZw5WVNHDFT3l8YpX0De/x2wkx+++0YnT/ylZi3vszoUeEi5iIKa0fcOOfP56dTZDPX9eIN+P3BSNf5/knf4xFm3/Q+fOKvIW4ItiNQmbNYH0PK7NcYoM/NC/7WlS5e65v6Ljo7WoUPXT1ySkpIUGhrqtvz3m6lejdkXDLg7TnG3FlDCV1uuuk+bKhH6+tcDOpthcjEy5KaK9e5S2Rp3qFh0rMrVrKeOg0bo8L4/tX3jD1aHBg9bumCOatatr7Cit1odCjxk58GTajd6tR4au1afrtmjVx+qqjLFCri2m8v+6HZIMuLPc6+x2TQwlieAtWvX1ksvvaQpU6Zo5cqVuvfeeyVdmCA6PDz8uscPHjxYx48fd1ui7uri7bAt9WyzMmoYV0T9pm/Swcv+hXhRtRKFFFMkP82/NhNSuIhCi4brSOp/rQ4FHnQgda82bfhRzVvfb3Uo8KBzGUa7D5/SL3+m6Y1F2/SffWnq2rCUDv11oVWraIh7FT+sYKAO/3XlP/OBnLI8ARw9erQ2bNigfv36aciQIYqLi5MkzZo1S/Xr17/u8U6nU4UKFXJb8nLzb/zdZdSkXFE9NeNn7bvGwI42VSK0JfUvbT94Mhejg9VO/XVcaUcOMCgkj1m2aK5CbwlT7XoNrQ4FXuSQQ4H5/LTnyGkdSDujBmWLurYF+DtUp3SYNvxxzLoA8ziHw+G1xRdZ3gewatWqSklJybL+tddek7+/vwUR+a7nmsepeYVi+tcXm3XqbIbCCgRIkk6kZ+js+UzXfvkD/dW0/K16Z8UOq0KFh5w9c9qtmnfs4D6l7tqu4IIhCi5YSN/O/li31blTBW8J0/GDqfrmsw+Vv2CoytcmUcgrMjMztXzRXN11Txv5+1v+RzY8JL5lWX37n0Pad/yMCjj9dW+14qpTJkw9PlgnSfrouz/0ZNPS+uPQSe06dEpPNi2t0+cyNG/jXosjR17hs3+aBAUFWR2Cz+lQI1KSNK5TNbf1Ly3YqgX/f6oASWpe4VY5HNKSXw/kanzwvH07tuqTl59zfV76ybuSpKp3tlDL7s/o4J4dSvluic6cPKGCt4SpVMXq6vDUC3IG57cqZHjYz+t/0MH9qWrWqp3VocCDihR0amTHqipWyKm/zpzT1n1/qccH67T6t8OSpAkrdioowF8J91e8MBH0nuPqPmEdcwB6ka9W6rzFYczl3UxzV0ZGht5880199tln2r17t86ede/fcOTIkRyfs/7Ibz0VHv4Gnmwaa3UIyEW3R9K8bSftRq+yOgTkom0jrXsDWIEHJ3nt3CdnPe61c98oy/sADh8+XKNGjdJDDz2k48ePKz4+Xh06dJCfn58SExOtDg8AANiBw4tLDowfP15Vq1Z1jWuoV6+eFi5c6NrerVu3LH0M77jjjhzfruUJ4NSpUzVhwgQ999xzypcvnzp16qSJEydq2LBhWrt2rdXhAQAA5JoSJUrolVde0bp167Ru3To1bdpU7dq10+bNm137tGzZUvv27XMtCxYsyPF1LO8DmJqa6noNXMGCBXX8+IVXmrVp00ZDhw61MjQAAGATvtIHsG3btm6fX375ZY0fP15r165VpUqVJF2YASUiIuKmrmN5BbBEiRLat2+fJCkuLk6LFy+WJCUnJ8vpdFoZGgAAsAlvTgOTnp6utLQ0t+Xyt5hdSUZGhqZPn66TJ0+qXr16rvUrVqxQsWLFVK5cOfXs2VMHDuR80KflCeD999+vZcuWSZKeeeYZDR06VGXLltVjjz2m7t27WxwdAADAzbnSW8uSkpKuun9KSooKFiwop9OpJ598Ul988YUqVqwoSWrVqpWmTp2q5cuX64033lBycrKaNm2arYTyUpaPAr7c2rVrtXr1asXFxem++27snZeMArYXRgHbC6OA7YVRwPZi5SjgQh0/9tq5D370cJYEzel0XrWl8+zZs9q9e7eOHTum2bNna+LEiVq5cqUrCbzUvn37FBMTo+nTp6tDhw7ZjsnyPoCXu+OOO25oNAsAAIAvulaydyWBgYGuN6PVrl1bycnJeuutt/Tee+9l2bd48eKKiYnRb7/9lqOYLEkA586dm+19b7QKCAAAkF2+MgjkSowxV23iPXz4sPbs2aPixYvn6JyWJIDt27fP1n4Oh0MZGcx6DgAA7OH5559Xq1atFB0drb/++kvTp0/XihUrtGjRIp04cUKJiYl64IEHVLx4ce3atUvPP/+8ihYtqvvvvz9H17EkAczMzLz+TgAAALnFRwqA+/fv16OPPqp9+/YpNDRUVatW1aJFi9S8eXOdPn1aKSkp+vjjj3Xs2DEVL15cd911l2bMmKGQkJAcXceyPoDLly9Xv379tHbtWhUqVMht2/Hjx1W/fn29++67uvPOOy2KEAAAIHd98MEHV90WHBysr7/+2iPXsWwamNGjR6tnz55Zkj9JCg0NVa9evTRq1CgLIgMAAHbjzXkAfZFlCeDPP/+sli2vPty7RYsWWr9+fS5GBAAAYA+WNQHv379fAQEBV92eL18+HTx4MBcjAgAAduWrlTpvsawCGBUVpZSUlKtu37RpU46HNAMAANwImoBzSevWrTVs2DCdOXMmy7bTp08rISFBbdq0sSAyAACAvM2yJuAXXnhBn3/+ucqVK6d+/fqpfPnycjgc2rJli8aOHauMjAwNGTLEqvAAAICN+GqlzlssSwDDw8O1evVq9e7dW4MHD9bFVxI7HA7dc889GjdunMLDw60KDwAAIM+y9F3AMTExWrBggY4ePart27fLGKOyZcuqcOHCVoYFAADsxl4FQGsTwIsKFy6s22+/3eowAAAAbMEnEkAAAAAr2a0PoGWjgAEAAGANKoAAAMD27FYBJAEEAAC2Z7cEkCZgAAAAm6ECCAAAYK8CIBVAAAAAu6ECCAAAbI8+gAAAAMjTqAACAADbowIIAACAPI0KIAAAsD27VQBJAAEAgO3ZLQGkCRgAAMBmqAACAADYqwBIBRAAAMBuqAACAADbow8gAAAA8jQqgAAAwPaoAAIAACBPowIIAABsz24VQBJAAAAAe+V/NAEDAADYDRVAAABge3ZrAqYCCAAAYDNUAAEAgO1RAQQAAECeRgUQAADYHhVAAAAA5GlUAAEAgO3ZrQJIAggAAGCv/I8mYAAAALvJkxXA5fGNrA4BAOAB6//dwuoQYBN2awKmAggAAGAzebICCAAAkBNUAAEAAJCnUQEEAAC2Z7MCIBVAAAAAXzF+/HhVrVpVhQoVUqFChVSvXj0tXLjQtd0Yo8TEREVGRio4OFhNmjTR5s2bc3wdEkAAAGB7DofDa0tOlChRQq+88orWrVundevWqWnTpmrXrp0ryRs5cqRGjRqlMWPGKDk5WREREWrevLn++uuvnN2vMcbk6Ii/gTPnrY4AAOAJ5zIyrQ4BuSjEaV1dqtygRV4797aRLW/q+LCwML322mvq3r27IiMj1b9/f/3rX/+SJKWnpys8PFyvvvqqevXqle1zUgEEAADwovT0dKWlpbkt6enp1z0uIyND06dP18mTJ1WvXj3t3LlTqampatHif/NjOp1ONW7cWKtXr85RTCSAAADA9rzZBJyUlKTQ0FC3JSkp6aqxpKSkqGDBgnI6nXryySf1xRdfqGLFikpNTZUkhYeHu+0fHh7u2pZdjAIGAADwosGDBys+Pt5tndPpvOr+5cuX18aNG3Xs2DHNnj1bXbt21cqVK13bL+9XaIzJcV9DEkAAAGB73pwGxul0XjPhu1xgYKDi4uIkSbVr11ZycrLeeustV7+/1NRUFS9e3LX/gQMHslQFr4cmYAAAAB9mjFF6erpiY2MVERGhJUuWuLadPXtWK1euVP369XN0TiqAAADA9vz8fGMm6Oeff16tWrVSdHS0/vrrL02fPl0rVqzQokWL5HA41L9/f40YMUJly5ZV2bJlNWLECOXPn1+dO3fO0XVIAAEAAHzE/v379eijj2rfvn0KDQ1V1apVtWjRIjVv3lySNGjQIJ0+fVp9+vTR0aNHVbduXS1evFghISE5ug7zAAIAfBbzANqLlfMAVhqy2Gvn3vxyi+vvlMuoAAIAANvL6SjavzsGgQAAANgMFUAAAGB7NisAUgEEAACwGyqAAADA9ugDCAAAgDyNCiAAALA9KoAAAADI06gAAgAA27NZAZAEEAAAgCZgAAAA5GlUAAEAgO3ZrABIBRAAAMBuqAACAADbow8gAAAA8jQqgAAAwPZsVgCkAggAAGA3VAABAIDt0QcQAAAAeRoVQAAAYHs2KwCSAAIAANAEDAAAgDyNCiAAALA9mxUAra0Ajhs3TnfffbceeughLV++3G3boUOHVLp0aYsiAwAAyLssSwDffvttDRw4ULfddpucTqdat26tpKQk1/aMjAz98ccfVoUHAABsxOFweG3xRZY1Ab/33nuaMGGCOnfuLEnq06eP2rdvr9OnT+vFF1+0KiwAAIA8z7IEcOfOnapfv77rc7169bR8+XI1a9ZM586dU//+/a0KDQAA2IyPFuq8xrIEsGjRotqzZ49KlSrlWlepUiUtX75cTZs21X//+1+rQgMAAMjTLOsD2LBhQ82ePTvL+ooVK2rZsmVatGiRBVEBAAA7og9gLvm///s/rV+//orbKlWqpG+++UazZs3K5agAAIAd+Wie5jUOY4yxOghPO3Pe6ggAAJ5wLiPT6hCQi0Kc1s1O1/D1VV4793fP3em1c98oy98EsmjRIn333Xeuz2PHjlX16tXVuXNnHT161MLIAACAXditCdjyBHDgwIFKS0uTJKWkpGjAgAFq3bq1duzYofj4eIujAwAAyHssfxXczp07VbFiRUnS7Nmz1aZNG40YMUIbNmxQ69atLY4OAADYga9W6rzF8gpgYGCgTp06JUlaunSpWrRoIUkKCwtzVQYBAADgOZZXABs2bKj4+Hg1aNBAP/74o2bMmCFJ2rZtm0qUKGFxdAAAwA5sVgC0vgI4ZswY5cuXT7NmzdL48eMVFRUlSVq4cKFatmxpcXQAAAB5D9PAAAB8FtPA2IuV08A0Gb3aa+de0b/+9XfKZZZXADds2KCUlBTX5y+//FLt27fX888/r7Nnz1oYGQAAsAuHw3uLL7I8AezVq5e2bdsmSdqxY4c6duyo/Pnza+bMmRo0aJDF0QEAAOQ9lieA27ZtU/Xq1SVJM2fOVKNGjTRt2jRNnjz5iu8KBgAA8DS7TQRt+ShgY4wyMy/08Vi6dKnatGkjSYqOjtahQ4eue3x6errS09Pdz+nvlNPp9HywAAAAeYDlFcDatWvrpZde0pQpU7Ry5Urde++9ki5MEB0eHn7d45OSkhQaGuq2vPZqkrfDBgAAeYjd+gBaPgp406ZN6tKli3bv3q34+HglJCRIkp566ikdPnxY06ZNu+bxVAABIO9iFLC9WDkKuNk7a7x27mVP1fPauW+U5Qng1Zw5c0b+/v4KCAjI+bFMAwMAeQIJoL1YmQA2H7PWa+de0u8Or537RlneBHw1QUFBN5T8AQAA/F0lJSXp9ttvV0hIiIoVK6b27dtr69atbvt069Yty0CTO+7IWZJpeQKYkZGh119/XXXq1FFERITCwsLcFgAAAG/zlT6AK1euVN++fbV27VotWbJE58+fV4sWLXTy5Em3/Vq2bKl9+/a5lgULFuToOpaPAh4+fLgmTpyo+Ph4DR06VEOGDNGuXbs0Z84cDRs2zOrwAACADfjKdC2LFi1y+zxp0iQVK1ZM69evV6NGjVzrnU6nIiIibvg6llcAp06dqgkTJui5555Tvnz51KlTJ02cOFHDhg3T2rXea48HAADIDenp6UpLS3NbLh/AejXHjx+XpCytoitWrFCxYsVUrlw59ezZUwcOHMhRTJYngKmpqapSpYokqWDBgq4bbdOmjebPn29laAAAwCb8HN5brjRlXVLS9aesM8YoPj5eDRs2VOXKlV3rW7VqpalTp2r58uV64403lJycrKZNm2Y7qZR8oAm4RIkS2rdvn0qWLKm4uDgtXrxYNWvWVHJyMlO5AACAv73BgwcrPj7ebV12cpx+/fpp06ZN+u6779zWP/zww67/rly5smrXrq2YmBjNnz9fHTp0yFZMlieA999/v5YtW6a6devqmWeeUadOnfTBBx9o9+7devbZZ60ODwAA2IA3+wA6nTmfn/ipp57S3Llz9e2336pEiRLX3Ld48eKKiYnRb7/9lu3zW54AvvLKK67/fvDBB1WiRAmtXr1acXFxuu+++yyMDAAAIHcZY/TUU0/piy++0IoVKxQbG3vdYw4fPqw9e/aoePHi2b6O5Qng5e64444cz2UDAABwM3xkELD69u2radOm6csvv1RISIhSU1MlSaGhoQoODtaJEyeUmJioBx54QMWLF9euXbv0/PPPq2jRorr//vuzfR1LEsC5c+dme1+qgAAAwC7Gjx8vSWrSpInb+kmTJqlbt27y9/dXSkqKPv74Yx07dkzFixfXXXfdpRkzZigkJCTb17EkAWzfvn229nM4HMrIyPBuMAAAwPYc8o0S4PXe0BscHKyvv/76pq9jSQKYmcm7HQEAgO/w8438L9dYNg/g8uXLVbFiRaWlpWXZdvz4cVWqVEmrVq2yIDIAAIC8zbIEcPTo0erZs6cKFSqUZVtoaKh69eqlUaNGWRAZAACwG4fD4bXFF1mWAP78889q2bLlVbe3aNFC69evz8WIAAAA7MGyaWD279+vgICAq27Ply+fDh48mIsRAQAAu/LRQp3XWFYBjIqKUkpKylW3b9q0KUcTGgIAACB7PJIAHjt2LMfHtG7dWsOGDdOZM2eybDt9+rQSEhLUpk0bD0QHAABwbX4Oh9cWX5TjBPDVV1/VjBkzXJ8feughFSlSRFFRUfr555+zfZ4XXnhBR44cUbly5TRy5Eh9+eWXmjt3rl599VWVL19eR44c0ZAhQ3IaHgAAAK4jx30A33vvPX3yySeSpCVLlmjJkiVauHChPvvsMw0cOFCLFy/O1nnCw8O1evVq9e7dW4MHD3ZNfOhwOHTPPfdo3LhxCg8Pz2l4AAAAOeajhTqvyXECuG/fPkVHR0uS5s2bp4ceekgtWrRQqVKlVLdu3RydKyYmRgsWLNDRo0e1fft2GWNUtmxZFS5cOKdhAQAA3DBfna7FW3LcBFy4cGHt2bNHkrRo0SLdfffdki68uuRGX9tWuHBh3X777apTpw7JHwAAgJfluALYoUMHde7cWWXLltXhw4fVqlUrSdLGjRsVFxfn8QABAAC8zWYFwJwngG+++aZKlSqlPXv2aOTIkSpYsKCkC03Dffr08XiAAAAA8CyHuTj6Ig85c97qCAAAnnAuI9PqEJCLQpyWTU+shz/6yWvnntG1htfOfaOyVQGcO3dutk9433333XAwAAAA8L5sJYDt27fP1skcDscNDwQBAACwis26AGYvAczMpAQPAACQV+R4EMilzpw5o6CgIE/FAgAAYAnmAbyOjIwM/fvf/1ZUVJQKFiyoHTt2SJKGDh2qDz74wOMBAgAAeJufw3uLL8pxAvjyyy9r8uTJGjlypAIDA13rq1SpookTJ3o0OAAAAHhejhPAjz/+WO+//766dOkif39/1/qqVavqP//5j0eDAwAAyA0Oh8Nriy/KcQL43//+94pv/MjMzNS5c+c8EhQAAAC8J8cJYKVKlbRq1aos62fOnKkaNXxvokMAAIDrcTi8t/iiHI8CTkhI0KOPPqr//ve/yszM1Oeff66tW7fq448/1rx587wRIwAAADwoxxXAtm3basaMGVqwYIEcDoeGDRumLVu26KuvvlLz5s29ESMAAIBX2a0P4A3NA3jPPffonnvu8XQsAAAAyAU3PBH0unXrtGXLFjkcDlWoUEG1atXyZFwAAAC5xlfn6/OWHCeAf/75pzp16qTvv/9et9xyiyTp2LFjql+/vj799FNFR0d7OkYAAACv8tWmWm/JcR/A7t2769y5c9qyZYuOHDmiI0eOaMuWLTLGqEePHt6IEQAAAB6U4wrgqlWrtHr1apUvX961rnz58nrnnXfUoEEDjwYHAACQG+xV/7uBCmDJkiWvOOHz+fPnFRUV5ZGgAAAA4D05TgBHjhypp556SuvWrZMxRtKFASHPPPOMXn/9dY8HCAAA4G1+DofXFl/kMBezuGsoXLiwW+fIkydP6vz588qX70IL8sX/LlCggI4cOeK9aLPpzHmrIwAAeMK5jEyrQ0AuCnHmuC7lMf+c8YvXzj3x4cpeO/eNylYfwNGjR3s5DAAAAOv4aKHOa7KVAHbt2tXbcQAAACCX3PBE0JJ0+vTpLANCChUqdFMBAQAA5DbmAbyOkydPql+/fipWrJgKFiyowoULuy0AAADwbTlOAAcNGqTly5dr3LhxcjqdmjhxooYPH67IyEh9/PHH3ogRAADAqxwO7y2+KMdNwF999ZU+/vhjNWnSRN27d9edd96puLg4xcTEaOrUqerSpYs34gQAAPAaX52uxVtyXAE8cuSIYmNjJV3o73dx2peGDRvq22+/9Wx0AAAA8LgcJ4ClS5fWrl27JEkVK1bUZ599JulCZfCWW27xZGwAAAC5wm5NwDlOAB9//HH9/PPPkqTBgwe7+gI+++yzGjhwoMcDBAAAgGdl600g17J7926tW7dOZcqUUbVq1TwV103hTSAAkDfwJhB7sfJNIH2/2OK1c4+9v4LXzn2jbvqbLlmypDp06KCwsDB1797dEzEBAADAi25qIuhLHTlyRB999JE+/PBDT53yhjV85RurQ0AualS1uNUhIBc1jr3F6hCQix4fudzqEJCLjkzpbNm1ras9WsNu9wsAAOCzkpKSdPvttyskJETFihVT+/bttXXrVrd9jDFKTExUZGSkgoOD1aRJE23evDlH1yEBBAAAtudwOLy25MTKlSvVt29frV27VkuWLNH58+fVokULnTx50rXPyJEjNWrUKI0ZM0bJycmKiIhQ8+bN9ddff2X7Oh5rAgYAAPi78vOR6VoWLVrk9nnSpEkqVqyY1q9fr0aNGskYo9GjR2vIkCHq0KGDJOmjjz5SeHi4pk2bpl69emXrOtlOAC9e5GqOHTuW3VMBAADYRnp6utLT093WOZ1OOZ3O6x57/PhxSVJYWJgkaefOnUpNTVWLFi3cztW4cWOtXr062wlgtpuAQ0NDr7nExMTosccey+7pAAAAfIafw3tLUlJSlrwpKSnpujEZYxQfH6+GDRuqcuXKkqTU1FRJUnh4uNu+4eHhrm3Zke0K4KRJk7J9UgAAAFwwePBgxcfHu63LTvWvX79+2rRpk7777rss2y7vW2iMyVF/Q/oAAgAA28vpYI2cyG5z76WeeuopzZ07V99++61KlCjhWh8RESHpQiWwePH/TYN24MCBLFXBa2EUMAAAgI8wxqhfv376/PPPtXz5csXGxrptj42NVUREhJYsWeJad/bsWa1cuVL169fP9nWoAAIAANvzlVHAffv21bRp0/Tll18qJCTE1a8vNDRUwcHBcjgc6t+/v0aMGKGyZcuqbNmyGjFihPLnz6/OnbM/kTYJIAAAgI8YP368JKlJkyZu6ydNmqRu3bpJkgYNGqTTp0+rT58+Onr0qOrWravFixcrJCQk29chAQQAALbnxS6AOWKMue4+DodDiYmJSkxMvOHr3FAfwClTpqhBgwaKjIzUH3/8IUkaPXq0vvzyyxsOBAAAwCp+DofXFl+U4wRw/Pjxio+PV+vWrXXs2DFlZGRIkm655RaNHj3a0/EBAADAw3KcAL7zzjuaMGGChgwZIn9/f9f62rVrKyUlxaPBAQAA5AY/Ly6+KMdx7dy5UzVq1Miy3ul0ur2oGAAAAL4pxwlgbGysNm7cmGX9woULVbFiRU/EBAAAkKscDu8tvijHo4AHDhyovn376syZMzLG6Mcff9Snn36qpKQkTZw40RsxAgAAwINynAA+/vjjOn/+vAYNGqRTp06pc+fOioqK0ltvvaWOHTt6I0YAAACv8tXRut5yQ/MA9uzZUz179tShQ4eUmZmpYsWKeTouAAAAeMlNTQRdtGhRT8UBAABgGZsVAHOeAMbGxspxjW9px44dNxUQAABAbvOVdwHnlhwngP3793f7fO7cOf30009atGiRBg4c6Km4AAAA4CU5TgCfeeaZK64fO3as1q1bd9MBAQAA5Da7DQLx2ATVrVq10uzZsz11OgAAAHjJTQ0CudSsWbMUFhbmqdMBAADkGpsVAHOeANaoUcNtEIgxRqmpqTp48KDGjRvn0eAAAADgeTlOANu3b+/22c/PT7feequaNGmi2267zVNxAQAA5BpGAV/D+fPnVapUKd1zzz2KiIjwVkwAAADwohwNAsmXL5969+6t9PR0b8UDAACQ6xxe/J8vyvEo4Lp16+qnn37yRiwAAACW8HN4b/FFOe4D2KdPHw0YMEB//vmnatWqpQIFCrhtr1q1qseCAwAAgOdlOwHs3r27Ro8erYcffliS9PTTT7u2ORwOGWPkcDiUkZHh+SgBAAC8yFcrdd6S7QTwo48+0iuvvKKdO3d6Mx4AAAB4WbYTQGOMJCkmJsZrwQAAAFjBYbOZoHM0CMRuXw4AAEBelKNBIOXKlbtuEnjkyJGbCggAACC30QfwGoYPH67Q0FBvxQIAAIBckKMEsGPHjipWrJi3YpEk7d+/X+np6SpZsqRXrwMAAHCR3Xq5ZbsPoKf7//3111965JFHFBMTo65du+rs2bPq27evihcvrtjYWDVu3FhpaWkevSYAAMCV+DkcXlt8UbYTwIujgD3l+eef1/r16/Xcc89p9+7deuihh/Ttt99q1apVWrFihY4cOaJXX33Vo9cEAABADpqAMzMzPXrhL7/8Uh999JHuuusuPfDAAypRooS+/PJLNWjQQJL06quvKj4+Xi+//LJHrwsAAHA5uw0CyfG7gD3lwIEDiouLkyRFRkYqODhY5cuXd22vVKmS9uzZY1V4AAAAeZZlCWCRIkV08OBB1+d27drplltucX0+ceKEnE6nBZEBAAC7cTi8t/giyxLAqlWrKjk52fV52rRpbiOMk5OTVaFCBStCAwAAyNNyNA2MJ02dOlV+flfPP8PDw+n/BwAAcoWffLRU5yWWJYBhYWHX3N6qVatcigQAAMBeLGsCvmjRokX67rvvXJ/Hjh2r6tWrq3Pnzjp69KiFkQEAALugD2AuGzhwoGvC55SUFA0YMECtW7fWjh07FB8fb3F0AADADvwc3lt8kWVNwBft3LlTFStWlCTNnj1bbdq00YgRI7Rhwwa1bt3a4ugAAADyHssTwMDAQJ06dUqStHTpUj322GOSLvQR5FVwAAAgN/jqK9u8xfIEsGHDhoqPj1eDBg30448/asaMGZKkbdu2qUSJEhZHBwAAkPdY3gdwzJgxypcvn2bNmqXx48crKipKkrRw4UK1bNnS4ugAAIAd2G0QiOUVwJIlS2revHlZ1r/55psWRAMAAJD3WV4B3LBhg1JSUlyfv/zyS7Vv317PP/+8zp49a2FkAADALvwcDq8tvsjyBLBXr17atm2bJGnHjh3q2LGj8ufPr5kzZ2rQoEEWRwcAAJD3WJ4Abtu2TdWrV5ckzZw5U40aNdK0adM0efJkzZ49+7rHp6enKy0tzW3JPE/lEAAAZJ/d+gBangAaY5SZmSnpwjQwF+f+i46O1qFDh657fFJSkkJDQ92W1G+neTVmAACQt/h5cfFFlsdVu3ZtvfTSS5oyZYpWrlype++9V9KFCaLDw8Ove/zgwYN1/PhxtyWiUWdvhw0AAOAV3377rdq2bavIyEg5HA7NmTPHbXu3bt3kcDjcljvuuCNH17B8FPDo0aPVpUsXzZkzR0OGDFFcXJwkadasWapfv/51j3c6nXI6nW7r/PIFeiVWAACQNzl8qK325MmTqlatmh5//HE98MADV9ynZcuWmjRpkutzYGDOch/LE8CqVau6jQK+6LXXXpO/v78FEQEAAFinVatWatWq1TX3cTqdioiIuOFrWN4EfDVBQUEKCAiwOgwAAGADDi8uVxqwmp6eflPxrlixQsWKFVO5cuXUs2dPHThwIEfHW54AZmRk6PXXX1edOnUUERGhsLAwtwUAAODv7EoDVpOSkm74fK1atdLUqVO1fPlyvfHGG0pOTlbTpk1zlFRa3gQ8fPhwTZw4UfHx8Ro6dKiGDBmiXbt2ac6cORo2bJjV4QEAABvw5oTNgwcPVnx8vNu6y8cv5MTDDz/s+u/KlSurdu3aiomJ0fz589WhQ4dsncPyBHDq1KmaMGGC7r33Xg0fPlydOnVSmTJlVLVqVa1du1ZPP/201SECAADcsCsNWPWk4sWLKyYmRr/99lu2j7G8CTg1NVVVqlSRJBUsWFDHjx+XJLVp00bz58+3MjQAAGAT3uwD6G2HDx/Wnj17VLx48WwfY3kCWKJECe3bt0+SFBcXp8WLF0uSkpOTvZotAwAAXORLbwI5ceKENm7cqI0bN0q6MDfyxo0btXv3bp04cULPPfec1qxZo127dmnFihVq27atihYtqvvvvz/b17A8Abz//vu1bNkySdIzzzyjoUOHqmzZsnrsscfUvXt3i6MDAADIXevWrVONGjVUo0YNSVJ8fLxq1KihYcOGyd/fXykpKWrXrp3KlSunrl27qly5clqzZo1CQkKyfQ3L+wC+8sorrv9+8MEHVaJECa1evVpxcXG67777LIwMAADYhS9NBN2kSRMZY666/euvv77pa1ieAF7ujjvuyPHrTAAAAJB9liSAc+fOzfa+VAEBAIC3Wd4nLpdZkgC2b98+W/s5HA5lZGR4NxgAAACbsSQBzMzMtOKyAAAAV+RLfQBzg2UVz+XLl6tixYpKS0vLsu348eOqVKmSVq1aZUFkAAAAeZtlCeDo0aPVs2dPFSpUKMu20NBQ9erVS6NGjbIgMgAAYDd/54mgb4RlCeDPP/+sli1bXnV7ixYttH79+lyMCAAAwB4smwZm//79CggIuOr2fPny6eDBg7kYEQAAsCv6AOaSqKgopaSkXHX7pk2bcvROOwAAgBvl58XFF1kWV+vWrTVs2DCdOXMmy7bTp08rISFBbdq0sSAyAACAvM2yJuAXXnhBn3/+ucqVK6d+/fqpfPnycjgc2rJli8aOHauMjAwNGTLEqvAAAICN2K0J2LIEMDw8XKtXr1bv3r01ePBg1zvvHA6H7rnnHo0bN07h4eFWhQcAAJBnWfou4JiYGC1YsEBHjx7V9u3bZYxR2bJlVbhwYSvDAgAANmOv+p/FCeBFhQsX1u233251GAAAALbgEwkgAACAlWzWBdBnRycDAADAS6gAAgAA2/OzWS9AEkAAAGB7NAEDAAAgT6MCCAAAbM9hsyZgKoAAAAA2QwUQAADYHn0AAQAAkKdRAQQAALZnt2lgqAACAADYDBVAAABge3brA0gCCAAAbM9uCSBNwAAAADZDBRAAANgeE0EDAAAgT6MCCAAAbM/PXgVAKoAAAAB2QwUQAADYHn0AAQAAkKdRAQQAALZnt3kASQABAIDt0QQMAACAPI0KIAAAsD2mgQEAAECeRgUQAADYHn0AAQAAkKdRAQQAALZnt2lgqAACAADYDBVAAABgezYrAJIAAgAA+NmsDZgmYAAAAB/y7bffqm3btoqMjJTD4dCcOXPcthtjlJiYqMjISAUHB6tJkybavHlzjq6RJyuAcdG3WB0CctHJsxlWh4BcFHtLQatDQC46/ctqq0NArups2ZV9qf538uRJVatWTY8//rgeeOCBLNtHjhypUaNGafLkySpXrpxeeuklNW/eXFu3blVISEi2rpEnE0AAAIC/q1atWqlVq1ZX3GaM0ejRozVkyBB16NBBkvTRRx8pPDxc06ZNU69evbJ1DZqAAQAAHN5b0tPTlZaW5rakp6ffUJg7d+5UamqqWrRo4VrndDrVuHFjrV6d/Yo5CSAAAIAXJSUlKTQ01G1JSkq6oXOlpqZKksLDw93Wh4eHu7ZlB03AAADA9rz5KrjBgwcrPj7ebZ3T6bypczouG7VsjMmy7lpIAAEAALzI6XTedMJ3UUREhKQLlcDixYu71h84cCBLVfBaaAIGAAC253B4b/Gk2NhYRUREaMmSJa51Z8+e1cqVK1W/fv1sn4cKIAAAsD1fmgbmxIkT2r59u+vzzp07tXHjRoWFhalkyZLq37+/RowYobJly6ps2bIaMWKE8ufPr86dsz+NDgkgAACAD1m3bp3uuusu1+eL/Qe7du2qyZMna9CgQTp9+rT69Omjo0ePqm7dulq8eHG25wCUSAABAAB8qgTYpEkTGWOuut3hcCgxMVGJiYk3fA36AAIAANgMFUAAAGB73pwGxhdRAQQAALAZKoAAAMD2PD1di6+jAggAAGAzVAABAIDt2awASAIIAABgtwyQJmAAAACboQIIAABsj2lgAAAAkKdRAQQAALbHNDAAAADI06gAAgAA27NZAZAKIAAAgN1QAQQAALBZCZAEEAAA2B7TwAAAACBPowIIAABsj2lgAAAAkKdRAQQAALZnswIgFUAAAAC7oQIIAABgsxIgFUAAAACboQIIAABsj3kAAQAAkKdRAQQAALZnt3kASQABAIDt2Sz/owkYAADAbnwuARw+fLgOHTpkdRgAAMBOHF5cfJBlTcBpaWlZ1hlj9PLLL6tVq1YKDAyUJBUqVCi3QwMAAMjTLEsACxcufMX1xhjVq1dPxhg5HA5lZGTkcmQAAMBu7DYNjGUJYPHixVW9enUNGDBAfn4XWqKNMbr77rs1ceJExcbGWhUaAABAnmZZArhp0yb16NFD//73vzVlyhRFRUVJkhwOh+rUqaOKFStaFRoAALAZu00DY9kgkLCwMH3xxRf6xz/+oTp16ujTTz+1KhQAAABbsXwewN69e6tx48bq3LmzvvrqK6vDAQAANmSzAqBvTANTsWJF/fjjj4qIiFDlypUVHBxsdUgAAMBOmAbGGoGBgRo1apTVYQAAAOR5llcAFy1apO+++871eezYsapevbo6d+6so0ePWhgZAACwC4cX/+eLLE8ABw4c6JoUOiUlRfHx8WrdurV27Nih+Ph4i6MDAADIeyxvAt65c6drypfZs2erbdu2GjFihDZs2KDWrVtbHB0AALADpoHJZYGBgTp16pQkaenSpWrRooWkC9PEXOl1cQAAALg5llcAGzZsqPj4eDVo0EA//vijZsyYIUnatm2bSpQoYXF0AADADmxWALS+AjhmzBjly5dPs2bN0vjx411vBFm4cKFatmxpcXQAAAB5j+UVwJIlS2revHlZ1r/55psWRAMAAGzJZiVAyyuAGzZsUEpKiuvzl19+qfbt2+v555/X2bNnLYwMAADYBdPA5LJevXpp27ZtkqQdO3aoY8eOyp8/v2bOnKlBgwZZHB0AAEDuSUxMlMPhcFsiIiI8fh3LE8Bt27apevXqkqSZM2eqUaNGmjZtmiZPnqzZs2dbGxwAALAFh8N7S05VqlRJ+/btcy2XtpR6iuV9AI0xyszMlHRhGpg2bdpIkqKjo3Xo0KHrHp+enq709HS3dRnnzso/INDzwQIAAHhZvnz5vFL1u5TlFcDatWvrpZde0pQpU7Ry5Urde++9ki5MEB0eHn7d45OSkhQaGuq2bJn3obfDBgAAeYjDi0t6errS0tLclsuLV5f67bffFBkZqdjYWHXs2FE7duzw+P1angCOHj1aGzZsUL9+/TRkyBDFxcVJkmbNmqX69etf9/jBgwfr+PHjbkuFNt29HTYAAEC2XKlYlZSUdMV969atq48//lhff/21JkyYoNTUVNWvX1+HDx/2aEwOY4zx6Bk95MyZM/L391dAQECOj+340U9eiAi+KrQAzf120rdujNUhIBfVve//rA4Buej0T2Msu/auw2e8du7iBR1ZKn5Op1NOp/O6x548eVJlypTRoEGDFB8f77GYLO8DeDVBQUFWhwAAAHDTspvsXUmBAgVUpUoV/fbbbx6NyfIm4IyMDL3++uuqU6eOIiIiFBYW5rYAAAB4m6/OA5ienq4tW7aoePHiHrrTCyxPAIcPH65Ro0bpoYce0vHjxxUfH68OHTrIz89PiYmJVocHAABswFemgXnuuee0cuVK7dy5Uz/88IMefPBBpaWlqWvXrh69X8sTwKlTp2rChAl67rnnlC9fPnXq1EkTJ07UsGHDtHbtWqvDAwAAyDV//vmnOnXqpPLly6tDhw4KDAzU2rVrFRPj2f7PlvcBTE1NVZUqVSRJBQsW1PHjxyVJbdq00dChQ60MDQAA2ISvvLBt+vTpuXIdyyuAJUqU0L59+yRJcXFxWrx4sSQpOTn5hjtMAgAA4OosTwDvv/9+LVu2TJL0zDPPaOjQoSpbtqwee+wxde/OfH4AAMD7fKUPYG6xvAn4lVdecf33gw8+qBIlSmj16tWKi4vTfffdZ2FkAAAAeZPlCeDl7rjjDt1xxx1WhwEAAGzFR0t1XmJJAjh37txs70sVEAAAwLMsSQDbt2+frf0cDocyMjK8GwwAALA9X+2r5y2WJICZmZlWXBYAAOCKbJb/WTcKePny5apYsaLS0tKybDt+/LgqVaqkVatWWRAZAABA3mZZAjh69Gj17NlThQoVyrItNDRUvXr10qhRoyyIDAAA2I3dpoGxLAH8+eef1bJly6tub9GihdavX5+LEQEAANiDZdPA7N+/XwEBAVfdni9fPh08eDAXIwIAAHblsFkvQMsqgFFRUUpJSbnq9k2bNql48eK5GBEAAIA9WJYAtm7dWsOGDdOZM2eybDt9+rQSEhLUpk0bCyIDAAC24/Di4oMsawJ+4YUX9Pnnn6tcuXLq16+fypcvL4fDoS1btmjs2LHKyMjQkCFDrAoPAAAgz7IsAQwPD9fq1avVu3dvDR48WMYYSRcmf77nnns0btw4hYeHWxUeAACwER8t1HmNpe8CjomJ0YIFC3T06FFt375dxhiVLVtWhQsXtjIsAABgM746XYu3WJoAXlS4cGHdfvvtVocBAABgCz6RAAIAAFiJaWAAAACQp1EBBAAAsFcBkAogAACA3VABBAAAtmezAiAVQAAAALuhAggAAGyPeQABAABshmlgAAAAkKdRAQQAALZntyZgKoAAAAA2QwIIAABgMySAAAAANkMfQAAAYHv0AQQAAECeRgUQAADYnt3mASQBBAAAtkcTMAAAAPI0KoAAAMD2bFYApAIIAABgN1QAAQAAbFYCpAIIAABgM1QAAQCA7dltGhgqgAAAADZDBRAAANge8wACAAAgT6MCCAAAbM9mBUASQAAAALtlgDQBAwAA2AwJIAAAsD2HF/93I8aNG6fY2FgFBQWpVq1aWrVqlUfvlwQQAADAh8yYMUP9+/fXkCFD9NNPP+nOO+9Uq1attHv3bo9dgwQQAADYnsPhvSWnRo0apR49euif//ynKlSooNGjRys6Olrjx4/32P2SAAIAAHhRenq60tLS3Jb09PQr7nv27FmtX79eLVq0cFvfokULrV692mMx5clRwNO71rA6hFyXnp6upKQkDR48WE6n0+pw4GU8b3ux8/M+/dMYq0PIdXZ+3lYK8mJGlPhSkoYPH+62LiEhQYmJiVn2PXTokDIyMhQeHu62Pjw8XKmpqR6LyWGMMR47GyyTlpam0NBQHT9+XIUKFbI6HHgZz9teeN72wvPOe9LT07NU/JxO5xUT/L179yoqKkqrV69WvXr1XOtffvllTZkyRf/5z388ElOerAACAAD4iqsle1dStGhR+fv7Z6n2HThwIEtV8GbQBxAAAMBHBAYGqlatWlqyZInb+iVLlqh+/foeuw4VQAAAAB8SHx+vRx99VLVr11a9evX0/vvva/fu3XryySc9dg0SwDzC6XQqISGBDsM2wfO2F563vfC88fDDD+vw4cN68cUXtW/fPlWuXFkLFixQTEyMx67BIBAAAACboQ8gAACAzZAAAgAA2AwJIAAAgM2QAPowh8OhOXPmWB0GcgnP21543vbC84avIQG0UGpqqp566imVLl1aTqdT0dHRatu2rZYtW5brsTzzzDOqVauWnE6nqlevnuvXtwNfed4///yzOnXqpOjoaAUHB6tChQp66623cjUGO/CV53348GG1bNlSkZGRrjj69euntLS0XI0jr/OV532pw4cPq0SJEnI4HDp27JhlccA3MQ2MRXbt2qUGDRrolltu0ciRI1W1alWdO3dOX3/9tfr27euxV71klzFG3bt31w8//KBNmzbl6rXtwJee9/r163Xrrbfqk08+UXR0tFavXq0nnnhC/v7+6tevX67FkZf50vP28/NTu3bt9NJLL+nWW2/V9u3b1bdvXx05ckTTpk3LtTjyMl963pfq0aOHqlatqv/+97+WXB8+zsASrVq1MlFRUebEiRNZth09etQYY4wk88UXX7jWDxo0yJQtW9YEBweb2NhY88ILL5izZ8+6tm/cuNE0adLEFCxY0ISEhJiaNWua5ORkY4wxu3btMm3atDG33HKLyZ8/v6lYsaKZP39+lmsnJCSYatWqefRe4bvP+6I+ffqYu+66yzM3C59/3m+99ZYpUaKEZ24WPvm8x40bZxo3bmyWLVtmJLniAC6iAmiBI0eOaNGiRXr55ZdVoECBLNtvueWWKx4XEhKiyZMnKzIyUikpKerZs6dCQkI0aNAgSVKXLl1Uo0YNjR8/Xv7+/tq4caMCAgIkSX379tXZs2f17bffqkCBAvr1119VsGBBr90j/ufv8LyPHz+usLCwm79Z+Pzz3rt3rz7//HM1btzYMzdsc774vH/99Ve9+OKL+uGHH7Rjxw7P3zTyBqszUDv64YcfjCTz+eefX3M/XfYvxsuNHDnS1KpVy/U5JCTETJ48+Yr7VqlSxSQmJl43NiqAnufLz9sYY1avXm0CAgLM4sWLs7U/rs1Xn3fHjh1NcHCwkWTatm1rTp8+fc39kT2+9rzPnDljqlataqZMmWKMMeabb76hAogrYhCIBcz/f/mKw+HI0XGzZs1Sw4YNFRERoYIFC2ro0KHavXu3a3t8fLz++c9/6u6779Yrr7yi33//3bXt6aef1ksvvaQGDRooISGBfn65yJef9+bNm9WuXTsNGzZMzZs3v4G7w+V89Xm/+eab2rBhg+bMmaPff/9d8fHxN3iHuJSvPe/BgwerQoUKeuSRR27yzpDnWZt/2tPhw4eNw+EwI0aMuOZ+uuRfjGvWrDH+/v7mpZdeMsnJyWbbtm3mxRdfNKGhoW7HbN261YwaNco0b97cBAYGuv2rdPfu3Wb8+PHm/vvvNwEBAebtt9/Ock0qgJ7nq8978+bNplixYub555/3yH3iAl993pdatWqVkWT27t17w/eJC3zteVerVs34+fkZf39/4+/vb/z8/Iwk4+/vb4YNG+bRe8ffGwmgRVq2bJmjTsOvv/66KV26tNt+PXr0yPIHxqU6duxo2rZte8Vt//d//2eqVKmSZT0JoHf42vP+5ZdfTLFixczAgQNzdiPIFl973pf79ttvjSSzc+fOa94HsseXnvf27dtNSkqKa/nwww+NJLN69Wqzf//+nN8c8iyagC0ybtw4ZWRkqE6dOpo9e7Z+++03bdmyRW+//bbq1auXZf+4uDjt3r1b06dP1++//663335bX3zxhWv76dOn1a9fP61YsUJ//PGHvv/+eyUnJ6tChQqSpP79++vrr7/Wzp07tWHDBi1fvty1TZK2b9+ujRs3KjU1VadPn9bGjRu1ceNGnT171vtfhg340vPevHmz7rrrLjVv3lzx8fFKTU1VamqqDh48mDtfhg340vNesGCBJk2apF9++UW7du3SggUL1Lt3bzVo0EClSpXKle8jr/Ol512mTBlVrlzZtcTGxkqSKlSooGLFiuXCt4G/DaszUDvbu3ev6du3r4mJiTGBgYEmKirK3Hfffeabb74xxmTtNDxw4EBTpEgRU7BgQfPwww+bN9980/UvxvT0dNOxY0cTHR1tAgMDTWRkpOnXr5+ro3e/fv1MmTJljNPpNLfeeqt59NFHzaFDh1znbty4sZGUZaFC4Dm+8rwTEhKu+KxjYmJy8dvI+3zleS9fvtzUq1fPhIaGmqCgIFO2bFnzr3/9i0EBHuYrz/tyDALB1TiM+f89WAEAAGALNAEDAADYDAkgAACAzZAAAgAA2AwJIAAAgM2QAAIAANgMCSAAAIDNkAACAADYDAkgAACAzZAAArhhiYmJql69uutzt27d1L59+1yPY9euXXI4HNq4caPXrnH5vd6I3IgTALKDBBDIY7p16yaHwyGHw6GAgACVLl1azz33nE6ePOn1a7/11luaPHlytvbN7WSoSZMm6t+/f65cCwB8XT6rAwDgeS1bttSkSZN07tw5rVq1Sv/85z918uRJjR8/Psu+586dU0BAgEeuGxoa6pHzAAC8iwogkAc5nU5FREQoOjpanTt3VpcuXTRnzhxJ/2vK/PDDD1W6dGk5nU4ZY3T8+HE98cQTKlasmAoVKqSmTZvq559/djvvK6+8ovDwcIWEhKhHjx46c+aM2/bLm4AzMzP16quvKi4uTk6nUyVLltTLL78sSYqNjZUk1ahRQw6HQ02aNHEdN2nSJFWoUEFBQUG67bbbNG7cOLfr/Pjjj6pRo4aCgoJUu3Zt/fTTTzf9nf3rX/9SuXLllD9/fpUuXVpDhw7VuXPnsuz33nvvKTo6Wvnz59c//vEPHTt2zG379WK/1NGjR9WlSxfdeuutCg4OVtmyZTVp0qSbvhcAuB4qgIANBAcHuyUz27dv12effabZs2fL399fknTvvfcqLCxMCxYsUGhoqN577z01a9ZM27ZtU1hYmD777DMlJCRo7NixuvPOOzVlyhS9/fbbKl269FWvO3jwYE2YMEFvvvmmGjZsqH379uk///mPpAtJXJ06dbR06VJVqlRJgYGBkqQJEyYoISFBY8aMUY0aNfTTTz+pZ8+eKlCggLp27aqTJ0+qTZs2atq0qT755BPt3LlTzzzzzE1/RyEhIZo8ebIiIyOVkpKinj17KiQkRIMGDcryvX311VdKS0tTjx491LdvX02dOjVbsV9u6NCh+vXXX7Vw4UIVLVpU27dv1+nTp2/6XgDgugyAPKVr166mXbt2rs8//PCDKVKkiHnooYeMMcYkJCSYgIAAc+DAAdc+y5YtM4UKFTJnzpxxO1eZMmXMe++9Z4wxpl69eubJJ5902163bl1TrVq1K147LS3NOJ1OM2HChCvGuXPnTiPJ/PTTT27ro6OjzbRp09zW/fvf/zb16tUzxhjz3nvvmbCwMHPy5EnX9vHjx1/xXJdq3LixeeaZZ666/XIjR440tWrVcn1OSEgw/v7+Zs+ePa51CxcuNH5+fmbfvn3Ziv3ye27btq15/PHHsx0TAHgKFUAgD5o3b54KFiyo8+fP69y5c2rXrp3eeecd1/aYmBjdeuutrs/r16/XiRMnVKRIEbfznD59Wr///rskacuWLXryySfdtterV0/ffPPNFWPYsmWL0tPT1axZs2zHffDgQe3Zs0c9evRQz549XevPnz/v6l+4ZcsWVatWTfnz53eL42bNmjVLo0eP1vbt23XixAmdP39ehQoVctunZMmSKlGihNt1MzMztXXrVvn7+1839sv17t1bDzzwgDZs2KAWLVqoffv2ql+//k3fCwBcDwkgkAfdddddGj9+vAICAhQZGZllkEeBAgXcPmdmZqp48eJasWJFlnPdcsstNxRDcHBwjo/JzMyUdKEptW7dum7bLjZVG2NuKJ5rWbt2rTp27Kjhw4frnnvuUWhoqKZPn6433njjmsc5HA7X/2cn9su1atVKf/zxh+bPn6+lS5eqWbNm6tu3r15//XUP3BUAXB0JIJAHFShQQHFxcdnev2bNmkpNTVW+fPlUqlSpK+5ToUIFrV27Vo899phr3dq1a696zrJlyyo4OFjLli3TP//5zyzbL/b5y8jIcK0LDw9XVFSUduzYoS5dulzxvBUrVtSUKVN0+vRpV5J5rTiy4/vvv1dMTIyGDBniWvfHH39k2W/37t3au3evIiMjJUlr1qyRn5+fypUrl63Yr+TWW29Vt27d1K1bN915550aOHAgCSAAryMBBKC7775b9erVU/v27fXqq6+qfPny2rt3rxYsWKD27durdu3aeuaZZ9S1a1fVrl1bDRs21NSpU7V58+arDgIJCgrSv/71Lw0aNEiBgYFq0KCBDh48qM2bN6tHjx4qVqyYgoODtWjRIpUoUUJBQUEKDQ1VYmKinn76aRUqVEitWrVSenq61q1bp6NHjyo+Pl6dO3fWkCFD1KNHD73wwgvatWtXthOmgwcPZpl3MCIiQnFxcdq9e7emT5+u22+/XfPnz9cXX3xxxXvq2rWrXn/9daWlpenpp5/WQw89pIiICEm6buyXGzZsmGrVqqVKlSopPT1d8+bNU4UKFbJ1LwBwU6zuhAjAsy4fBHK5hIQEt4EbF6WlpZmnnnrKREZGmoCAABMdHW26dOlidu/e7drn5ZdfNkWLFjUFCxY0Xbt2NYMGDbrqIBBjjMnIyDAvvfSSiYmJMQEBAaZkyZJmxIgRru0TJkww0dHRxs/PzzRu3Ni1furUqaZ69eomMDDQFC5c2DRq1Mh8/vnnru1r1qwx1apVM4GBgaZ69epm9uzZ2RoEIinLkpCQYIwxZuDAgaZIkSKmYMGC5uGHHzZvvvmmCQ0NzfK9jRs3zkRGRpqgoCDToUMHc+TIEbfrXCv2yweB/Pvf/zYVKlQwwcHBJiwszLRr187s2LHjqvcAAJ7iMMYLHWoAAADgs5gIGgAAwGZIAAEAAGyGBBAAAMBmSAABAABshgQQAADAZkgAAQAAbIYEEAAAwGZIAAEAAGyGBBAAAMBmSAABAABshgQQAADAZv4fjgHdRbzVIVoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['Class1', 'Class2', 'Class3', 'Class4']\n",
    "\n",
    "for feature_type, outputs in model_outputs.items():\n",
    "    cm = confusion_matrix(outputs['val_preds'], outputs['val_labels'])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    modality = feature_type.split('_')[1]  # Extract modality name from feature_type\n",
    "    plt.title(f'Confusion Matrix for {modality.capitalize()} Model')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'optimizer': 'Adam',\n",
       " 'criterion': 'CrossEntropyLoss',\n",
       " 'epochs': 30,\n",
       " 'batch_size': 16,\n",
       " 'patience': 15,\n",
       " 'weight_decay': 0,\n",
       " 'validation_accuracy': 0.5634328358208955}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
