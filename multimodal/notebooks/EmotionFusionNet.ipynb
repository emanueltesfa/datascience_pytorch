{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VisualClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(256, 4)\n",
    "        self.bn2 = nn.BatchNorm1d(4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=4, hidden_dim=256):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudialClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudialClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 16)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.bn2 = nn.BatchNorm1d(4)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, criterion, device, num_epochs=50, patience=10):\n",
    "\n",
    "    \"\"\"\n",
    "    Trains and validates the model.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The PyTorch model to train.\n",
    "    - dataloaders (dict): A dictionary containing 'train' and 'val' DataLoaders.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to use for training.\n",
    "    - criterion (torch.nn.Module): The loss function.\n",
    "    - num_epochs (int): The number of epochs to train for.\n",
    "    - patience (int): The patience for early stopping.\n",
    "    \"\"\"\n",
    "    best_val_f1 = -float('inf')  \n",
    "    patience_counter = 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        val_probs = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders['val']:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "                val_probs.extend(outputs.cpu().numpy())\n",
    "\n",
    "\n",
    "        val_accuracy = np.mean(np.array(val_preds) == np.array(val_labels))\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='micro')\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1  \n",
    "            patience_counter = 0  \n",
    "            # print(f\"Validation F1 improved. Saving model...\")\n",
    "            # torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "            # print(f'Validation F1 did not improve. Patience: {patience_counter}/{patience}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break  \n",
    "\n",
    "\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}, Best Validation F1 Score: {best_val_f1:.4f}')\n",
    "    \n",
    "    return val_accuracy, best_val_f1, np.array(val_probs), np.array(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_pool_features(df, feature_types, base_path=\"../data/\"):\n",
    "    \"\"\"\n",
    "    Extracts features from specified columns in the DataFrame, applies mean pooling,\n",
    "    and updates the DataFrame with new columns for these processed features.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): The pandas DataFrame containing the features.\n",
    "    - feature_types (dict): A dictionary mapping from 'visual' and 'audio' to their respective column names in df.\n",
    "    - base_path (str): Base path where the feature files are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    for key, column in feature_types.items():\n",
    "        features_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_path = row[column]\n",
    "            features = np.load(f\"{base_path}{file_path}\")\n",
    "            features_list.append(np.mean(features, axis=0) if key != 'text' else features)\n",
    "        \n",
    "        df[f'extracted_{key}_features'] = features_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets_and_loaders(df, feature_columns, label_column='emotion_labels', batch_size = 4, test_size = 0.2):\n",
    "    \"\"\"\n",
    "    Prepares datasets and dataloaders for training and validation.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): The pandas DataFrame containing the pooled features and labels.\n",
    "    - feature_columns (list): List of column names for the features to be used.\n",
    "    - label_column (str): The column name where the label data is stored.\n",
    "    - batch_size (int): Batch size for the dataloaders.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary of dataloaders for training and validation for each feature type.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloaders = {}\n",
    "    y = torch.tensor(df[label_column].values, dtype = torch.long)\n",
    "\n",
    "    for feature_type in feature_columns:\n",
    "        X = np.array(df[feature_type].tolist(), dtype = np.float32)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = test_size, random_state = 42)\n",
    "        \n",
    "        train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train), y_train)\n",
    "        val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val), y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "        \n",
    "        dataloaders[f'{feature_type}_train'] = train_loader\n",
    "        dataloaders[f'{feature_type}_val'] = val_loader\n",
    "\n",
    "    return dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Class Imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/dataset.csv')\n",
    "\n",
    "labels = df['emotion_labels'].values\n",
    "classes = np.unique(labels)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights_tensor = class_weights_tensor.to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with extracted_visual_features:\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5299\n",
      "Training with extracted_audio_features:\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.5784\n",
      "Training with extracted_text_features:\n",
      "Validation Accuracy: 0.3321, Best Validation F1 Score: 0.3470\n"
     ]
    }
   ],
   "source": [
    "model_aud = AudialClassifier()\n",
    "model_aud = model_aud.to(device)\n",
    "\n",
    "model_vis = VisualClassifier()\n",
    "model_vis = model_vis.to(device)\n",
    "\n",
    "\n",
    "model_text = TextClassifier()\n",
    "model_text = model_text.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "\n",
    "feature_types = {'visual': 'visual_features', 'audio': 'acoustic_features', 'text':'lexical_features'}\n",
    "extract_and_pool_features(df, feature_types)\n",
    "\n",
    "feature_columns = ['extracted_visual_features', 'extracted_audio_features','extracted_text_features']\n",
    "dataloaders = prepare_datasets_and_loaders(df, feature_columns, batch_size = 16)\n",
    "\n",
    "optimizer_aud = optim.Adam(model_aud.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "optimizer_vis = optim.Adam(model_vis.parameters(), lr = 0.001, weight_decay = 0)\n",
    "optimizer_text = optim.Adam(model_vis.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "\n",
    "\n",
    "models_optimizers = {\n",
    "    'extracted_visual_features': (model_vis, optimizer_vis),\n",
    "    'extracted_audio_features': (model_aud, optimizer_aud),\n",
    "    'extracted_text_features': (model_text, optimizer_text),\n",
    "}\n",
    "\n",
    "model_outputs = {}\n",
    "for feature_type, (model, optimizer) in models_optimizers.items():\n",
    "    print(f\"Training with {feature_type}:\")\n",
    "    val_accuracy, best_val_f1, val_preds, val_labels = train_model(\n",
    "        model, \n",
    "        {'train': dataloaders[f'{feature_type}_train'], 'val': dataloaders[f'{feature_type}_val']}, \n",
    "        optimizer, criterion, device = device, num_epochs = 30, patience = 15)\n",
    "        \n",
    "    model_outputs[feature_type] = {\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'val_preds': val_preds,\n",
    "        'val_labels': val_labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_outputs['extracted_text_features']['val_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAM GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'optimizer': [optim.Adam],\n",
    "    'criterion': [nn.CrossEntropyLoss],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [4, 16, 32],\n",
    "    'patience': [5, 10, 15],\n",
    "    'weight_decay': [0, 1e-4, 1e-2],\n",
    "}\n",
    "\n",
    "\n",
    "def get_optimizer(optimizer_class, parameters, lr, weight_decay, momentum=None):\n",
    "    if optimizer_class == optim.Adam:\n",
    "        return optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_class == optim.SGD:\n",
    "        # Ensure momentum is provided for SGD; otherwise, default to 0\n",
    "        return optim.SGD(parameters, lr=lr, momentum=momentum if momentum is not None else 0, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def get_criterion(criterion_class):\n",
    "    if criterion_class == nn.CrossEntropyLoss:\n",
    "        return nn.CrossEntropyLoss()\n",
    "    elif criterion_class == nn.NLLLoss:\n",
    "        return nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(df, feature_columns, param_grid, device='cuda'):\n",
    "    max_vis_acc, max_aud_acc, max_text_acc = -np.inf, -np.inf, -np.inf\n",
    "    best_params_vis, best_params_aud, best_params_text = None, None, None\n",
    "\n",
    "    combinations = list(product(*param_grid.values()))\n",
    "\n",
    "    for combination in tqdm(combinations):\n",
    "        lr, optimizer_class, criterion_class, epochs, batch_size, patience, wd = combination\n",
    "        \n",
    "        dataloaders = prepare_datasets_and_loaders(df, feature_columns, batch_size=batch_size)\n",
    "        \n",
    "        model_vis = VisualClassifier().to(device)\n",
    "        optimizer_vis = optim.Adam(model_vis.parameters(), lr=lr, weight_decay=wd)\n",
    "        \n",
    "        model_aud = AudialClassifier().to(device)\n",
    "        optimizer_aud = optim.Adam(model_aud.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        model_text = TextClassifier().to(device)\n",
    "        optimizer_text = optim.Adam(model_text.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        \n",
    "        models_optimizers = {\n",
    "            'extracted_visual_features': (model_vis, optimizer_vis),\n",
    "            'extracted_audio_features': (model_aud, optimizer_aud),\n",
    "            'extracted_text_features': (model_text, optimizer_text),\n",
    "        }\n",
    "\n",
    "        for feature_type, (model, optimizer) in models_optimizers.items():\n",
    "            print(f\"\\nTraining {feature_type.split('_')[1].capitalize()} Model with lr={lr}, optimizer={optimizer_class.__name__}, criterion={criterion_class.__name__}, epochs={epochs}, batch_size={batch_size}, Patience={patience}, Weight decay={wd}\")\n",
    "            val_accuracy, best_val_f1, val_preds, val_labels = train_model(\n",
    "                model, \n",
    "                {'train': dataloaders[f'{feature_type}_train'], 'val': dataloaders[f'{feature_type}_val']}, \n",
    "                optimizer, criterion, device=device, num_epochs=epochs, patience=patience\n",
    "            )\n",
    "\n",
    "            if feature_type == 'extracted_visual_features' and val_accuracy > max_vis_acc:\n",
    "                max_vis_acc = val_accuracy\n",
    "                best_params_vis = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "            \n",
    "            elif feature_type == 'extracted_audio_features' and val_accuracy > max_aud_acc:\n",
    "                max_aud_acc = val_accuracy\n",
    "                best_params_aud = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "            \n",
    "            elif feature_type == 'extracted_text_features' and val_accuracy > max_text_acc:\n",
    "                max_text_acc = val_accuracy\n",
    "                best_params_text = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "\n",
    "    return best_params_vis, best_params_aud, best_params_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/162 [00:46<2:04:57, 46.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6754\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4030, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/162 [01:32<2:03:47, 46.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4366, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4627, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/162 [02:21<2:06:11, 47.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/162 [03:08<2:04:47, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/162 [03:57<2:05:16, 47.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4515\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 6/162 [04:57<2:15:12, 52.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/162 [05:45<2:10:40, 50.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5858, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 8/162 [06:31<2:05:58, 49.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/162 [07:15<2:00:55, 47.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 10/162 [07:26<1:31:46, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/162 [07:37<1:12:01, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/162 [07:48<58:25, 23.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/162 [08:00<48:49, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 14/162 [08:11<42:22, 17.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 15/162 [08:22<37:47, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6455, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4328, Best Validation F1 Score: 0.4701\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 16/162 [08:34<34:25, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 17/162 [08:45<32:15, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4590, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 18/162 [08:56<30:33, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 19/162 [09:02<25:37, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 20/162 [09:09<22:22,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4627, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 21/162 [09:15<19:58,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4440, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 22/162 [09:21<18:14,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 23/162 [09:28<17:05,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.4739\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4291, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 24/162 [09:34<16:13,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4254, Best Validation F1 Score: 0.4366\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 25/162 [09:40<15:31,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 26/162 [09:47<15:05,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27/162 [09:53<14:46,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 28/162 [11:01<56:11, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 29/162 [12:11<1:25:18, 38.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5597, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 30/162 [13:21<1:45:21, 47.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 31/162 [14:29<1:57:44, 53.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 32/162 [15:39<2:07:12, 58.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 33/162 [16:49<2:13:26, 62.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 34/162 [17:57<2:16:21, 63.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 35/162 [19:07<2:19:00, 65.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 36/162 [20:16<2:20:27, 66.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 37/162 [20:35<1:48:56, 52.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5000\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4664\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 38/162 [20:53<1:27:16, 42.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 39/162 [21:12<1:12:11, 35.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 40/162 [21:31<1:01:16, 30.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 41/162 [21:49<53:55, 26.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 42/162 [22:08<48:50, 24.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 43/162 [22:27<44:47, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 44/162 [22:45<42:13, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 45/162 [23:04<40:24, 20.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 46/162 [23:15<33:56, 17.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6493, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 47/162 [23:25<29:33, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6642\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 48/162 [23:36<26:33, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5000\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 49/162 [23:47<24:33, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 50/162 [23:57<22:52, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 51/162 [24:07<21:41, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6642\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 52/162 [24:18<20:38, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 53/162 [24:28<20:00, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 54/162 [24:39<19:33, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.5746\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 55/162 [25:20<35:27, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 56/162 [26:02<47:02, 26.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4440\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 57/162 [26:44<54:46, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 58/162 [27:25<59:13, 34.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 59/162 [28:07<1:02:47, 36.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3657, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5634, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 60/162 [28:49<1:04:58, 38.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 61/162 [29:30<1:05:45, 39.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 62/162 [30:12<1:06:41, 40.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4216, Best Validation F1 Score: 0.4403\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 63/162 [30:55<1:07:03, 40.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 64/162 [31:06<51:53, 31.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 65/162 [31:17<41:29, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 66/162 [31:28<34:11, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 67/162 [31:40<29:19, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 68/162 [31:52<25:48, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 69/162 [32:03<23:13, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 70/162 [32:15<21:13, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 71/162 [32:26<19:53, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 72/162 [32:38<19:01, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 73/162 [32:44<15:58, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 74/162 [32:51<13:53,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 75/162 [32:58<12:57,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 76/162 [33:05<11:53,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 77/162 [33:12<11:23,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 78/162 [33:20<11:07,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 79/162 [33:27<10:29,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 80/162 [33:34<10:10,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 81/162 [33:41<09:51,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 82/162 [34:56<36:54, 27.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 83/162 [36:13<55:44, 42.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4291, Best Validation F1 Score: 0.4664\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 84/162 [37:29<1:08:14, 52.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 85/162 [38:44<1:15:53, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 86/162 [40:00<1:21:27, 64.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3881, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 87/162 [41:16<1:24:50, 67.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 88/162 [42:31<1:26:11, 69.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 89/162 [43:47<1:27:12, 71.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 90/162 [45:04<1:28:08, 73.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 91/162 [45:24<1:08:01, 57.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6493, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 92/162 [45:45<54:10, 46.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 93/162 [46:05<44:24, 38.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 94/162 [46:25<37:26, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 95/162 [46:46<32:38, 29.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 96/162 [47:07<29:21, 26.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 97/162 [47:28<27:08, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 98/162 [47:49<25:25, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 99/162 [48:09<24:01, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 100/162 [48:21<20:00, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 101/162 [48:32<17:16, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 102/162 [48:43<15:18, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 103/162 [48:55<13:50, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 104/162 [49:06<12:50, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 105/162 [49:19<12:25, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 106/162 [49:30<11:42, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 107/162 [49:42<11:13, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 108/162 [49:53<10:48, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 109/162 [50:38<19:26, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.3993, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 110/162 [51:25<25:30, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3955\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 111/162 [52:11<29:19, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5634, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 112/162 [52:57<31:31, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6157\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4478\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 113/162 [53:44<33:00, 40.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3433\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 114/162 [54:30<33:46, 42.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 115/162 [55:15<33:48, 43.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5597, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 116/162 [1:40:47<10:51:32, 849.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4328\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 117/162 [1:42:10<7:44:43, 619.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 118/162 [1:42:31<5:22:46, 440.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 119/162 [1:42:52<3:45:17, 314.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2948, Best Validation F1 Score: 0.4440\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 120/162 [1:43:14<2:38:35, 226.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6082\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 121/162 [1:43:35<1:52:48, 165.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 122/162 [1:43:57<1:21:19, 122.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3843, Best Validation F1 Score: 0.4104\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 123/162 [1:44:17<59:26, 91.45s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 124/162 [1:44:34<43:44, 69.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 125/162 [1:44:54<33:33, 54.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4142\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 126/162 [1:45:14<26:31, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 127/162 [1:45:26<20:07, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 128/162 [1:45:39<15:51, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.3507, Best Validation F1 Score: 0.4328\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 129/162 [1:45:55<13:20, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 130/162 [1:46:09<11:18, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6567, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 131/162 [1:46:21<09:35, 18.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4104\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 132/162 [1:46:34<08:24, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 133/162 [1:46:44<07:11, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6381, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 134/162 [1:46:53<06:06, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.3918, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 135/162 [1:47:04<05:31, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 136/162 [1:48:45<16:58, 39.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 137/162 [1:50:26<24:03, 57.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4254\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 138/162 [1:52:31<31:05, 77.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 139/162 [1:54:26<34:07, 89.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4216, Best Validation F1 Score: 0.4515\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 140/162 [1:56:23<35:39, 97.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3955\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 141/162 [1:58:34<37:35, 107.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 142/162 [2:00:40<37:41, 113.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 143/162 [2:02:59<38:13, 120.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4067\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 144/162 [2:04:45<34:54, 116.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 145/162 [2:05:11<25:16, 89.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 146/162 [2:05:37<18:46, 70.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 147/162 [2:06:04<14:19, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 148/162 [2:06:32<11:18, 48.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 149/162 [2:06:58<09:03, 41.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4254\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 150/162 [2:07:25<07:28, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 151/162 [2:07:51<06:13, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 152/162 [2:08:18<05:17, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4142\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 153/162 [2:08:44<04:31, 30.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 154/162 [2:08:59<03:25, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 155/162 [2:09:14<02:37, 22.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.3806, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 156/162 [2:09:29<02:00, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 157/162 [2:09:43<01:31, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 158/162 [2:09:58<01:08, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 159/162 [2:10:13<00:50, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 160/162 [2:10:28<00:32, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 161/162 [2:10:44<00:15, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.3731, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [2:11:00<00:00, 48.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6082\n",
      "Best Visual Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 50, 'batch_size': 32, 'patience': 15, 'weight_decay': 0, 'validation_accuracy': 0.5447761194029851}\n",
      "Best Audio Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 30, 'batch_size': 4, 'patience': 15, 'weight_decay': 0, 'validation_accuracy': 0.5970149253731343}\n",
      "Best Text Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 30, 'batch_size': 32, 'patience': 10, 'weight_decay': 0, 'validation_accuracy': 0.6567164179104478}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vis_params, aud_params, text_params = grid_search(df, feature_columns, param_grid, device='cuda')\n",
    "print(\"Best Visual Model Params:\", vis_params)\n",
    "print(\"Best Audio Model Params:\", aud_params)\n",
    "print(\"Best Text Model Params:\", text_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.0001,\n",
       "  'optimizer': 'Adam',\n",
       "  'criterion': 'CrossEntropyLoss',\n",
       "  'epochs': 30,\n",
       "  'batch_size': 4,\n",
       "  'patience': 5,\n",
       "  'weight_decay': 0,\n",
       "  'validation_accuracy': 0.5335820895522388},\n",
       " {'learning_rate': 0.0001,\n",
       "  'optimizer': 'Adam',\n",
       "  'criterion': 'CrossEntropyLoss',\n",
       "  'epochs': 30,\n",
       "  'batch_size': 4,\n",
       "  'patience': 5,\n",
       "  'weight_decay': 0,\n",
       "  'validation_accuracy': 0.5783582089552238})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_params , aud_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of alignment temporally and lack of similarity of shapes of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexConcatModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=4):\n",
    "        super(ComplexConcatModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc5 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1336, 2944)\n",
      "Validation Accuracy: 0.7276, Best Validation F1 Score: 0.7351\n"
     ]
    }
   ],
   "source": [
    "class ConcatDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        \"\"\"\n",
    "        features: Numpy array of concatenated features.\n",
    "        labels: Numpy array of labels.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Concatenate features\n",
    "concatenated_features = np.hstack((\n",
    "    np.array(df['extracted_visual_features'].tolist()),\n",
    "    np.array(df['extracted_audio_features'].tolist()),\n",
    "    np.array(df['extracted_text_features'].tolist())\n",
    "))\n",
    "\n",
    "print(concatenated_features.shape)\n",
    "labels = df['emotion_labels'].values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(concatenated_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state = 0,max_iter=1000).fit(X_train, y_train)\n",
    "yPred_clf = clf.predict(X_val)\n",
    "# print(accuracy_score(y_val, yPred_clf))\n",
    "\n",
    "\n",
    "train_dataset = ConcatDataset(X_train, y_train)\n",
    "val_dataset = ConcatDataset(X_val, y_val)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size = 16, shuffle = True),\n",
    "    'val': DataLoader(val_dataset, batch_size = 16, shuffle = False)\n",
    "}\n",
    "\n",
    "model = ComplexConcatModel(input_dim = concatenated_features.shape[1]).to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "\n",
    "_, _, _, _ = train_model(\n",
    "    model = model,\n",
    "    dataloaders = dataloaders,\n",
    "    optimizer = optimizer,\n",
    "    criterion = criterion,  # Make sure this is defined as shown before\n",
    "    device = device,\n",
    "    num_epochs = 50,\n",
    "    patience = 15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Late fusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704969/704969 [00:12<00:00, 58461.09it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_aud = model_outputs['extracted_audio_features']['val_preds']\n",
    "predictions_vis = model_outputs['extracted_visual_features']['val_preds']\n",
    "predictions_text = model_outputs['extracted_text_features']['val_preds']\n",
    "\n",
    "\n",
    "# final_predictions = (predictions_vis + predictions_aud + predictions_text) / 3\n",
    "weight_dict = {\n",
    "    'weight_vis': [i/100 for i in range(11, 100)],\n",
    "    'weight_aud': [i/100 for i in range(11, 100)],\n",
    "    'weight_text': [i/100 for i in range(11, 100)],\n",
    "}\n",
    "\n",
    "weight_combinations = list(product(*weight_dict.values()))\n",
    "max_params = -np.inf\n",
    "best_weights = None\n",
    "\n",
    "for weights in tqdm(weight_combinations):\n",
    "    # print(weights)\n",
    "    weight_vis, weight_aud, weight_text = weights\n",
    "    final_predictions_weighted = (weight_vis * predictions_vis + weight_aud * predictions_aud + weight_text * predictions_text)\n",
    "    final_predicted_classes = np.argmax(final_predictions_weighted, axis = 1)\n",
    "    acc = (np.mean(final_predicted_classes == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n",
    "    if acc > max_params:\n",
    "        max_params = acc\n",
    "        best_weights = weights\n",
    "# final_predicted_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13 0.25 0.12\n",
      "0.6343283582089553\n"
     ]
    }
   ],
   "source": [
    "predictions_aud = model_outputs['extracted_audio_features']['val_preds']\n",
    "predictions_vis = model_outputs['extracted_visual_features']['val_preds']\n",
    "predictions_text = model_outputs['extracted_text_features']['val_preds']\n",
    "\n",
    "\n",
    "# final_predictions = (predictions_vis + predictions_aud + predictions_text) / 3\n",
    "weight_vis, weight_aud, weight_text  = best_weights\n",
    "print(weight_vis, weight_aud, weight_text)\n",
    "final_predictions_weighted = (weight_vis * predictions_vis + weight_aud * predictions_aud + weight_text * predictions_text)\n",
    "final_predicted_classes = np.argmax(final_predictions_weighted, axis = 1)\n",
    "print(np.mean(final_predicted_classes == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n",
    "# final_predicted_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.208955223880597\n",
      "0.5186567164179104\n",
      "0.5186567164179104\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.argmax(model_outputs['extracted_text_features']['val_preds'], axis=1) == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n",
    "print(np.mean(np.argmax(model_outputs['extracted_visual_features']['val_preds'], axis=1) == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "print(np.mean(np.argmax(model_outputs['extracted_audio_features']['val_preds'] , axis=1) == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m classes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature_type, outputs \u001b[38;5;129;01min\u001b[39;00m model_outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 4\u001b[0m     cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_preds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_labels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      7\u001b[0m     sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, xticklabels\u001b[38;5;241m=\u001b[39mclasses, yticklabels\u001b[38;5;241m=\u001b[39mclasses)\n",
      "File \u001b[1;32mc:\\Users\\amant\\anaconda3\\envs\\pytorch_dl\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\amant\\anaconda3\\envs\\pytorch_dl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\amant\\anaconda3\\envs\\pytorch_dl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets"
     ]
    }
   ],
   "source": [
    "classes = ['Class1', 'Class2', 'Class3', 'Class4']\n",
    "\n",
    "for feature_type, outputs in model_outputs.items():\n",
    "    cm = confusion_matrix(outputs['val_preds'], outputs['val_labels'])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    modality = feature_type.split('_')[1]  # Extract modality name from feature_type\n",
    "    plt.title(f'Confusion Matrix for {modality.capitalize()} Model')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'optimizer': 'Adam',\n",
       " 'criterion': 'CrossEntropyLoss',\n",
       " 'epochs': 30,\n",
       " 'batch_size': 16,\n",
       " 'patience': 15,\n",
       " 'weight_decay': 0,\n",
       " 'validation_accuracy': 0.5634328358208955}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
