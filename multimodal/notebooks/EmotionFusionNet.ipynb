{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VisualClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(256, 4)\n",
    "        self.bn2 = nn.BatchNorm1d(4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=4, hidden_dim=256):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudialClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudialClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 16)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.bn2 = nn.BatchNorm1d(4)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, criterion, device, num_epochs=50, patience=10):\n",
    "\n",
    "    \"\"\"\n",
    "    Trains and validates the model.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The PyTorch model to train.\n",
    "    - dataloaders (dict): A dictionary containing 'train' and 'val' DataLoaders.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to use for training.\n",
    "    - criterion (torch.nn.Module): The loss function.\n",
    "    - num_epochs (int): The number of epochs to train for.\n",
    "    - patience (int): The patience for early stopping.\n",
    "    \"\"\"\n",
    "    best_val_f1 = -float('inf')  \n",
    "    patience_counter = 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        val_probs = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders['val']:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "                val_probs.extend(outputs.cpu().numpy())\n",
    "\n",
    "\n",
    "        val_accuracy = np.mean(np.array(val_preds) == np.array(val_labels))\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='micro')\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1  \n",
    "            patience_counter = 0  \n",
    "            # print(f\"Validation F1 improved. Saving model...\")\n",
    "            # torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "            # print(f'Validation F1 did not improve. Patience: {patience_counter}/{patience}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break  \n",
    "\n",
    "\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}, Best Validation F1 Score: {best_val_f1:.4f}')\n",
    "    \n",
    "    return val_accuracy, best_val_f1, np.array(val_probs), np.array(val_preds), np.array(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_pool_features(df, feature_types, base_path=\"../data/\"):\n",
    "    \"\"\"\n",
    "    Extracts features from specified columns in the DataFrame, applies mean pooling,\n",
    "    and updates the DataFrame with new columns for these processed features.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): The pandas DataFrame containing the features.\n",
    "    - feature_types (dict): A dictionary mapping from 'visual' and 'audio' to their respective column names in df.\n",
    "    - base_path (str): Base path where the feature files are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    for key, column in feature_types.items():\n",
    "        features_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_path = row[column]\n",
    "            features = np.load(f\"{base_path}{file_path}\")\n",
    "            features_list.append(np.mean(features, axis=0) if key != 'text' else features)\n",
    "        \n",
    "        df[f'extracted_{key}_features'] = features_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets_and_loaders(df, feature_columns, label_column='emotion_labels', batch_size = 4, test_size = 0.2):\n",
    "    \"\"\"\n",
    "    Prepares datasets and dataloaders for training and validation.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): The pandas DataFrame containing the pooled features and labels.\n",
    "    - feature_columns (list): List of column names for the features to be used.\n",
    "    - label_column (str): The column name where the label data is stored.\n",
    "    - batch_size (int): Batch size for the dataloaders.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary of dataloaders for training and validation for each feature type.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloaders = {}\n",
    "    y = torch.tensor(df[label_column].values, dtype = torch.long)\n",
    "\n",
    "    for feature_type in feature_columns:\n",
    "        X = np.array(df[feature_type].tolist(), dtype = np.float32)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = test_size, random_state = 42)\n",
    "        \n",
    "        train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train), y_train)\n",
    "        val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val), y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "        \n",
    "        dataloaders[f'{feature_type}_train'] = train_loader\n",
    "        dataloaders[f'{feature_type}_val'] = val_loader\n",
    "\n",
    "    return dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Class Imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/dataset.csv')\n",
    "\n",
    "labels = df['emotion_labels'].values\n",
    "classes = np.unique(labels)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights_tensor = class_weights_tensor.to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with extracted_visual_features:\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5336\n",
      "Training with extracted_audio_features:\n",
      "Early stopping triggered\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5597\n",
      "Training with extracted_text_features:\n",
      "Validation Accuracy: 0.3582, Best Validation F1 Score: 0.3769\n"
     ]
    }
   ],
   "source": [
    "model_aud = AudialClassifier()\n",
    "model_aud = model_aud.to(device)\n",
    "\n",
    "model_vis = VisualClassifier()\n",
    "model_vis = model_vis.to(device)\n",
    "\n",
    "\n",
    "model_text = TextClassifier()\n",
    "model_text = model_text.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "\n",
    "feature_types = {'visual': 'visual_features', 'audio': 'acoustic_features', 'text':'lexical_features'}\n",
    "extract_and_pool_features(df, feature_types)\n",
    "\n",
    "feature_columns = ['extracted_visual_features', 'extracted_audio_features','extracted_text_features']\n",
    "dataloaders = prepare_datasets_and_loaders(df, feature_columns, batch_size = 16)\n",
    "\n",
    "optimizer_aud = optim.Adam(model_aud.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "optimizer_vis = optim.Adam(model_vis.parameters(), lr = 0.001, weight_decay = 0)\n",
    "optimizer_text = optim.Adam(model_vis.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "\n",
    "\n",
    "models_optimizers = {\n",
    "    'extracted_visual_features': (model_vis, optimizer_vis),\n",
    "    'extracted_audio_features': (model_aud, optimizer_aud),\n",
    "    'extracted_text_features': (model_text, optimizer_text),\n",
    "}\n",
    "\n",
    "model_outputs = {}\n",
    "for feature_type, (model, optimizer) in models_optimizers.items():\n",
    "    print(f\"Training with {feature_type}:\")\n",
    "    val_accuracy, best_val_f1, val_probs, val_preds, val_labels = train_model(\n",
    "        model, \n",
    "        {'train': dataloaders[f'{feature_type}_train'], 'val': dataloaders[f'{feature_type}_val']}, \n",
    "        optimizer, criterion, device = device, num_epochs = 30, patience = 15)\n",
    "\n",
    "    model_outputs[feature_type] = {\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'val_preds': val_preds,\n",
    "        'val_labels': val_labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_outputs['extracted_text_features']['val_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAM GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'optimizer': [optim.Adam],\n",
    "    'criterion': [nn.CrossEntropyLoss],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [4, 16, 32],\n",
    "    'patience': [5, 10, 15],\n",
    "    'weight_decay': [0, 1e-4, 1e-2],\n",
    "}\n",
    "\n",
    "\n",
    "def get_optimizer(optimizer_class, parameters, lr, weight_decay, momentum=None):\n",
    "    if optimizer_class == optim.Adam:\n",
    "        return optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_class == optim.SGD:\n",
    "        # Ensure momentum is provided for SGD; otherwise, default to 0\n",
    "        return optim.SGD(parameters, lr=lr, momentum=momentum if momentum is not None else 0, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def get_criterion(criterion_class):\n",
    "    if criterion_class == nn.CrossEntropyLoss:\n",
    "        return nn.CrossEntropyLoss()\n",
    "    elif criterion_class == nn.NLLLoss:\n",
    "        return nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(df, feature_columns, param_grid, device='cuda'):\n",
    "    max_vis_acc, max_aud_acc, max_text_acc = -np.inf, -np.inf, -np.inf\n",
    "    best_params_vis, best_params_aud, best_params_text = None, None, None\n",
    "\n",
    "    combinations = list(product(*param_grid.values()))\n",
    "\n",
    "    for combination in tqdm(combinations):\n",
    "        lr, optimizer_class, criterion_class, epochs, batch_size, patience, wd = combination\n",
    "        \n",
    "        dataloaders = prepare_datasets_and_loaders(df, feature_columns, batch_size=batch_size)\n",
    "        \n",
    "        model_vis = VisualClassifier().to(device)\n",
    "        optimizer_vis = optim.Adam(model_vis.parameters(), lr=lr, weight_decay=wd)\n",
    "        \n",
    "        model_aud = AudialClassifier().to(device)\n",
    "        optimizer_aud = optim.Adam(model_aud.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        model_text = TextClassifier().to(device)\n",
    "        optimizer_text = optim.Adam(model_text.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        \n",
    "        models_optimizers = {\n",
    "            'extracted_visual_features': (model_vis, optimizer_vis),\n",
    "            'extracted_audio_features': (model_aud, optimizer_aud),\n",
    "            'extracted_text_features': (model_text, optimizer_text),\n",
    "        }\n",
    "\n",
    "        for feature_type, (model, optimizer) in models_optimizers.items():\n",
    "            print(f\"\\nTraining {feature_type.split('_')[1].capitalize()} Model with lr={lr}, optimizer={optimizer_class.__name__}, criterion={criterion_class.__name__}, epochs={epochs}, batch_size={batch_size}, Patience={patience}, Weight decay={wd}\")\n",
    "            val_accuracy, best_val_f1, val_probs, val_preds, val_labels = train_model(\n",
    "                model, \n",
    "                {'train': dataloaders[f'{feature_type}_train'], 'val': dataloaders[f'{feature_type}_val']}, \n",
    "                optimizer, criterion, device=device, num_epochs=epochs, patience=patience\n",
    "            )\n",
    "\n",
    "            if feature_type == 'extracted_visual_features' and val_accuracy > max_vis_acc:\n",
    "                max_vis_acc = val_accuracy\n",
    "                best_params_vis = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "            \n",
    "            elif feature_type == 'extracted_audio_features' and val_accuracy > max_aud_acc:\n",
    "                max_aud_acc = val_accuracy\n",
    "                best_params_aud = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "            \n",
    "            elif feature_type == 'extracted_text_features' and val_accuracy > max_text_acc:\n",
    "                max_text_acc = val_accuracy\n",
    "                best_params_text = {'learning_rate': lr, 'optimizer': optimizer_class.__name__, 'criterion': criterion_class.__name__, 'epochs': epochs, 'batch_size': batch_size, 'patience': patience, 'weight_decay': wd, 'validation_accuracy': val_accuracy}\n",
    "\n",
    "    return best_params_vis, best_params_aud, best_params_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/162 [00:46<2:04:57, 46.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6754\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4030, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/162 [01:32<2:03:47, 46.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4366, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4627, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/162 [02:21<2:06:11, 47.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/162 [03:08<2:04:47, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/162 [03:57<2:05:16, 47.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4515\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 6/162 [04:57<2:15:12, 52.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/162 [05:45<2:10:40, 50.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5858, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 8/162 [06:31<2:05:58, 49.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/162 [07:15<2:00:55, 47.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 10/162 [07:26<1:31:46, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/162 [07:37<1:12:01, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/162 [07:48<58:25, 23.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/162 [08:00<48:49, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 14/162 [08:11<42:22, 17.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 15/162 [08:22<37:47, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6455, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4328, Best Validation F1 Score: 0.4701\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 16/162 [08:34<34:25, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 17/162 [08:45<32:15, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4590, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 18/162 [08:56<30:33, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 19/162 [09:02<25:37, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 20/162 [09:09<22:22,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4627, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 21/162 [09:15<19:58,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4440, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 22/162 [09:21<18:14,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4776\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 23/162 [09:28<17:05,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.4739\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4291, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 24/162 [09:34<16:13,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4254, Best Validation F1 Score: 0.4366\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 25/162 [09:40<15:31,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 26/162 [09:47<15:05,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27/162 [09:53<14:46,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 28/162 [11:01<56:11, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 29/162 [12:11<1:25:18, 38.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5597, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 30/162 [13:21<1:45:21, 47.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 31/162 [14:29<1:57:44, 53.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 32/162 [15:39<2:07:12, 58.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 33/162 [16:49<2:13:26, 62.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 34/162 [17:57<2:16:21, 63.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 35/162 [19:07<2:19:00, 65.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6418, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 36/162 [20:16<2:20:27, 66.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 37/162 [20:35<1:48:56, 52.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5000\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4664\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 38/162 [20:53<1:27:16, 42.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 39/162 [21:12<1:12:11, 35.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 40/162 [21:31<1:01:16, 30.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 41/162 [21:49<53:55, 26.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 42/162 [22:08<48:50, 24.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 43/162 [22:27<44:47, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 44/162 [22:45<42:13, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 45/162 [23:04<40:24, 20.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 46/162 [23:15<33:56, 17.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6493, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 47/162 [23:25<29:33, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6642\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 48/162 [23:36<26:33, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5000\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 49/162 [23:47<24:33, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 50/162 [23:57<22:52, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 51/162 [24:07<21:41, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6642\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 52/162 [24:18<20:38, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 53/162 [24:28<20:00, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.4963\n",
      "\n",
      "Training Audio Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.0001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 54/162 [24:39<19:33, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.5746\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 55/162 [25:20<35:27, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 56/162 [26:02<47:02, 26.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4440\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 57/162 [26:44<54:46, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 58/162 [27:25<59:13, 34.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 59/162 [28:07<1:02:47, 36.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3657, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5634, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 60/162 [28:49<1:04:58, 38.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 61/162 [29:30<1:05:45, 39.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4851\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 62/162 [30:12<1:06:41, 40.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4216, Best Validation F1 Score: 0.4403\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 63/162 [30:55<1:07:03, 40.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 64/162 [31:06<51:53, 31.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 65/162 [31:17<41:29, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 66/162 [31:28<34:11, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 67/162 [31:40<29:19, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 68/162 [31:52<25:48, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 69/162 [32:03<23:13, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 70/162 [32:15<21:13, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 71/162 [32:26<19:53, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 72/162 [32:38<19:01, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 73/162 [32:44<15:58, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 74/162 [32:51<13:53,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 75/162 [32:58<12:57,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 76/162 [33:05<11:53,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 77/162 [33:12<11:23,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 78/162 [33:20<11:07,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 79/162 [33:27<10:29,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 80/162 [33:34<10:10,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 81/162 [33:41<09:51,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 82/162 [34:56<36:54, 27.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 83/162 [36:13<55:44, 42.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4291, Best Validation F1 Score: 0.4664\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5522, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 84/162 [37:29<1:08:14, 52.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6716\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 85/162 [38:44<1:15:53, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 86/162 [40:00<1:21:27, 64.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3881, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 87/162 [41:16<1:24:50, 67.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5112\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 88/162 [42:31<1:26:11, 69.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 89/162 [43:47<1:27:12, 71.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 90/162 [45:04<1:28:08, 73.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 91/162 [45:24<1:08:01, 57.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6493, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 92/162 [45:45<54:10, 46.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 93/162 [46:05<44:24, 38.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 94/162 [46:25<37:26, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 95/162 [46:46<32:38, 29.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 96/162 [47:07<29:21, 26.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 97/162 [47:28<27:08, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 98/162 [47:49<25:25, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5261\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 99/162 [48:09<24:01, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 100/162 [48:21<20:00, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 101/162 [48:32<17:16, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 102/162 [48:43<15:18, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 103/162 [48:55<13:50, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 104/162 [49:06<12:50, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 105/162 [49:19<12:25, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 106/162 [49:30<11:42, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 107/162 [49:42<11:13, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.001, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 108/162 [49:53<10:48, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4925\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 109/162 [50:38<19:26, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.3993, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 110/162 [51:25<25:30, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3955\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 111/162 [52:11<29:19, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5634, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 112/162 [52:57<31:31, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6007, Best Validation F1 Score: 0.6157\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4478\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 113/162 [53:44<33:00, 40.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3433\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 114/162 [54:30<33:46, 42.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.4888\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 115/162 [55:15<33:48, 43.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5597, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 116/162 [1:40:47<10:51:32, 849.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5336, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4328\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 117/162 [1:42:10<7:44:43, 619.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 118/162 [1:42:31<5:22:46, 440.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5037\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 119/162 [1:42:52<3:45:17, 314.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2948, Best Validation F1 Score: 0.4440\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 120/162 [1:43:14<2:38:35, 226.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6082\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 121/162 [1:43:35<1:52:48, 165.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5149\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 122/162 [1:43:57<1:21:19, 122.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.3843, Best Validation F1 Score: 0.4104\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 123/162 [1:44:17<59:26, 91.45s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.5970\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 124/162 [1:44:34<43:44, 69.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6119, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 125/162 [1:44:54<33:33, 54.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4142\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5821\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 126/162 [1:45:14<26:31, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5672, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 127/162 [1:45:26<20:07, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 128/162 [1:45:39<15:51, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6343, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.3507, Best Validation F1 Score: 0.4328\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 129/162 [1:45:55<13:20, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 130/162 [1:46:09<11:18, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6567, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5224, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 131/162 [1:46:21<09:35, 18.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4067, Best Validation F1 Score: 0.4104\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 132/162 [1:46:34<08:24, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 133/162 [1:46:44<07:11, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6381, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 134/162 [1:46:53<06:06, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6567\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.3918, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=30, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 135/162 [1:47:04<05:31, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4515, Best Validation F1 Score: 0.5075\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 136/162 [1:48:45<16:58, 39.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 137/162 [1:50:26<24:03, 57.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4254\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 138/162 [1:52:31<31:05, 77.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.4813\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5410, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 139/162 [1:54:26<34:07, 89.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5821, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4216, Best Validation F1 Score: 0.4515\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6007\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 140/162 [1:56:23<35:39, 97.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6231\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.3955\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 141/162 [1:58:34<37:35, 107.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5187\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 142/162 [2:00:40<37:41, 113.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5784, Best Validation F1 Score: 0.6194\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4142, Best Validation F1 Score: 0.4590\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5709, Best Validation F1 Score: 0.6045\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 143/162 [2:02:59<38:13, 120.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.6306\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4067\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.4478, Best Validation F1 Score: 0.5784\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=4, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 144/162 [2:04:45<34:54, 116.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3955, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 145/162 [2:05:11<25:16, 89.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6493\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5224\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 146/162 [2:05:37<18:46, 70.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6082, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5373, Best Validation F1 Score: 0.5634\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 147/162 [2:06:04<14:19, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4925, Best Validation F1 Score: 0.5858\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4851, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 148/162 [2:06:32<11:18, 48.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6343\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5373\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 149/162 [2:06:58<09:03, 41.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4254\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 150/162 [2:07:25<07:28, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5896\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5037, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 151/162 [2:07:51<06:13, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6194, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4963, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4701, Best Validation F1 Score: 0.5709\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 152/162 [2:08:18<05:17, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.2910, Best Validation F1 Score: 0.4142\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5261, Best Validation F1 Score: 0.5672\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=16, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 153/162 [2:08:44<04:31, 30.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5560, Best Validation F1 Score: 0.5933\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.4813, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n",
      "Validation Accuracy: 0.5112, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 154/162 [2:08:59<03:25, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6306, Best Validation F1 Score: 0.6418\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5149, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 155/162 [2:09:14<02:37, 22.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5896, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.3806, Best Validation F1 Score: 0.4552\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=5, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 156/162 [2:09:29<02:00, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6269, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.5299, Best Validation F1 Score: 0.5560\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n",
      "Validation Accuracy: 0.4664, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 157/162 [2:09:43<01:31, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6231, Best Validation F1 Score: 0.6604\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4776, Best Validation F1 Score: 0.5448\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5485, Best Validation F1 Score: 0.5522\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 158/162 [2:09:58<01:08, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5746, Best Validation F1 Score: 0.6381\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.4104, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n",
      "Validation Accuracy: 0.5075, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=10, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 159/162 [2:10:13<00:50, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5970, Best Validation F1 Score: 0.6269\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.5448, Best Validation F1 Score: 0.5597\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n",
      "Validation Accuracy: 0.4888, Best Validation F1 Score: 0.5336\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 160/162 [2:10:28<00:32, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6157, Best Validation F1 Score: 0.6455\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.5000, Best Validation F1 Score: 0.5485\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n",
      "Validation Accuracy: 0.4739, Best Validation F1 Score: 0.5299\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 161/162 [2:10:44<00:15, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5933, Best Validation F1 Score: 0.6530\n",
      "\n",
      "Training Visual Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.3731, Best Validation F1 Score: 0.4291\n",
      "\n",
      "Training Audio Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n",
      "Validation Accuracy: 0.5187, Best Validation F1 Score: 0.5410\n",
      "\n",
      "Training Text Model with lr=0.01, optimizer=Adam, criterion=CrossEntropyLoss, epochs=50, batch_size=32, Patience=15, Weight decay=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [2:11:00<00:00, 48.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6045, Best Validation F1 Score: 0.6082\n",
      "Best Visual Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 50, 'batch_size': 32, 'patience': 15, 'weight_decay': 0, 'validation_accuracy': 0.5447761194029851}\n",
      "Best Audio Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 30, 'batch_size': 4, 'patience': 15, 'weight_decay': 0, 'validation_accuracy': 0.5970149253731343}\n",
      "Best Text Model Params: {'learning_rate': 0.01, 'optimizer': 'Adam', 'criterion': 'CrossEntropyLoss', 'epochs': 30, 'batch_size': 32, 'patience': 10, 'weight_decay': 0, 'validation_accuracy': 0.6567164179104478}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vis_params, aud_params, text_params = grid_search(df, feature_columns, param_grid, device='cuda')\n",
    "print(\"Best Visual Model Params:\", vis_params)\n",
    "print(\"Best Audio Model Params:\", aud_params)\n",
    "print(\"Best Text Model Params:\", text_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.0001,\n",
       "  'optimizer': 'Adam',\n",
       "  'criterion': 'CrossEntropyLoss',\n",
       "  'epochs': 30,\n",
       "  'batch_size': 4,\n",
       "  'patience': 5,\n",
       "  'weight_decay': 0,\n",
       "  'validation_accuracy': 0.5335820895522388},\n",
       " {'learning_rate': 0.0001,\n",
       "  'optimizer': 'Adam',\n",
       "  'criterion': 'CrossEntropyLoss',\n",
       "  'epochs': 30,\n",
       "  'batch_size': 4,\n",
       "  'patience': 5,\n",
       "  'weight_decay': 0,\n",
       "  'validation_accuracy': 0.5783582089552238})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_params , aud_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of alignment temporally and lack of similarity of shapes of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexConcatModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=4):\n",
    "        super(ComplexConcatModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc5 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1336, 2944)\n",
      "Early stopping triggered\n",
      "Validation Accuracy: 0.6828, Best Validation F1 Score: 0.7388\n"
     ]
    }
   ],
   "source": [
    "class ConcatDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        \"\"\"\n",
    "        features: Numpy array of concatenated features.\n",
    "        labels: Numpy array of labels.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Concatenate features\n",
    "concatenated_features = np.hstack((\n",
    "    np.array(df['extracted_visual_features'].tolist()),\n",
    "    np.array(df['extracted_audio_features'].tolist()),\n",
    "    np.array(df['extracted_text_features'].tolist())\n",
    "))\n",
    "\n",
    "print(concatenated_features.shape)\n",
    "labels = df['emotion_labels'].values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(concatenated_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state = 0,max_iter=1000).fit(X_train, y_train)\n",
    "yPred_clf = clf.predict(X_val)\n",
    "# print(accuracy_score(y_val, yPred_clf))\n",
    "\n",
    "\n",
    "train_dataset = ConcatDataset(X_train, y_train)\n",
    "val_dataset = ConcatDataset(X_val, y_val)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size = 16, shuffle = True),\n",
    "    'val': DataLoader(val_dataset, batch_size = 16, shuffle = False)\n",
    "}\n",
    "\n",
    "model = ComplexConcatModel(input_dim = concatenated_features.shape[1]).to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay = 1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "\n",
    "_, _, _, _, _ = train_model(\n",
    "    model = model,\n",
    "    dataloaders = dataloaders,\n",
    "    optimizer = optimizer,\n",
    "    criterion = criterion,  # Make sure this is defined as shown before\n",
    "    device = device,\n",
    "    num_epochs = 50,\n",
    "    patience = 15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Late fusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704969/704969 [00:12<00:00, 58461.09it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_aud = model_outputs['extracted_audio_features']['val_preds']\n",
    "predictions_vis = model_outputs['extracted_visual_features']['val_preds']\n",
    "predictions_text = model_outputs['extracted_text_features']['val_preds']\n",
    "\n",
    "\n",
    "# final_predictions = (predictions_vis + predictions_aud + predictions_text) / 3\n",
    "weight_dict = {\n",
    "    'weight_vis': [i/100 for i in range(11, 100)],\n",
    "    'weight_aud': [i/100 for i in range(11, 100)],\n",
    "    'weight_text': [i/100 for i in range(11, 100)],\n",
    "}\n",
    "\n",
    "weight_combinations = list(product(*weight_dict.values()))\n",
    "max_params = -np.inf\n",
    "best_weights = None\n",
    "\n",
    "for weights in tqdm(weight_combinations):\n",
    "    # print(weights)\n",
    "    weight_vis, weight_aud, weight_text = weights\n",
    "    final_predictions_weighted = (weight_vis * predictions_vis + weight_aud * predictions_aud + weight_text * predictions_text)\n",
    "    final_predicted_classes = np.argmax(final_predictions_weighted, axis = 1)\n",
    "    acc = (np.mean(final_predicted_classes == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n",
    "    if acc > max_params:\n",
    "        max_params = acc\n",
    "        best_weights = weights\n",
    "# final_predicted_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13 0.25 0.12\n",
      "0.6343283582089553\n"
     ]
    }
   ],
   "source": [
    "predictions_aud = model_outputs['extracted_audio_features']['val_preds']\n",
    "predictions_vis = model_outputs['extracted_visual_features']['val_preds']\n",
    "predictions_text = model_outputs['extracted_text_features']['val_preds']\n",
    "\n",
    "\n",
    "# final_predictions = (predictions_vis + predictions_aud + predictions_text) / 3\n",
    "weight_vis, weight_aud, weight_text  = best_weights\n",
    "print(weight_vis, weight_aud, weight_text)\n",
    "final_predictions_weighted = (weight_vis * predictions_vis + weight_aud * predictions_aud + weight_text * predictions_text)\n",
    "final_predicted_classes = np.argmax(final_predictions_weighted, axis = 1)\n",
    "print(np.mean(final_predicted_classes == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n",
    "# final_predicted_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.208955223880597\n",
      "0.5186567164179104\n",
      "0.5186567164179104\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.argmax(model_outputs['extracted_text_features']['val_preds'], axis=1) == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n",
    "print(np.mean(np.argmax(model_outputs['extracted_visual_features']['val_preds'], axis=1) == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "print(np.mean(np.argmax(model_outputs['extracted_audio_features']['val_preds'] , axis=1) == model_outputs['extracted_text_features']['val_labels'] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['Class1', 'Class2', 'Class3', 'Class4']\n",
    "\n",
    "for feature_type, outputs in model_outputs.items():\n",
    "    cm = confusion_matrix(outputs['val_preds'], outputs['val_labels'])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    modality = feature_type.split('_')[1]  # Extract modality name from feature_type\n",
    "    plt.title(f'Confusion Matrix for {modality.capitalize()} Model')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'optimizer': 'Adam',\n",
       " 'criterion': 'CrossEntropyLoss',\n",
       " 'epochs': 30,\n",
       " 'batch_size': 16,\n",
       " 'patience': 15,\n",
       " 'weight_decay': 0,\n",
       " 'validation_accuracy': 0.5634328358208955}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
